Suma de variables i.i.d.
i.i.d.
Independientes 
IdÃ©nticamente 
Distribuidas

[DescripciÃ³n de la imagen: un libro con las palabras 'snavables id ']

Suma de variables i.i.d.
â€¢
Dos v.a.  continuas son independientes 
sii  
â€¢
Dos v.a.  discretas son independientes 
sii 
â€¢
Si dos v.a.   (continuas o discretas) son 
independientes, entonces

[DescripciÃ³n de la imagen: una nota con las palabras ','' y '']

Suma de variables i.i.d.
 v.a. i.i.d. con  y  
E [ ğ‘‹+ğ‘Œ]=E[ ğ‘‹]+E[ğ‘Œ]=2 ğœ‡
Var [ ğ‘‹+ğ‘Œ]=Var [ ğ‘‹]+Var [ğ‘Œ]+2COV [ ğ‘‹,ğ‘Œ]=2 ğœ2

[DescripciÃ³n de la imagen: una nota con las palabras y estÃ¡ en ella | TranscripciÃ³n de la imagen: Suma de variables 1.1.d.

V.a. |.1.d. con y

E X+Y | =E X+E Y =2u

Var | X +Y |= Var X +Var Y +2COV X, Y =20"]]

Suma de variables i.i.d.
v.a. i.i.d. con  y  
E[âˆ‘
ğ‘–=1
ğ‘›
ğ‘‹ğ‘–]=?
Var[âˆ‘
ğ‘–=1
ğ‘›
ğ‘‹ğ‘–]=?

[DescripciÃ³n de la imagen: un libro con una ecuaciÃ³n matemÃ¡tica en Ã©l | TranscripciÃ³n de la imagen: Suma de variables 1.1.d.

V.a. 1.1.d.con y]]

Suma de variables i.i.d.
v.a. i.i.d. con  y  
E[âˆ‘
ğ‘–=1
ğ‘›
ğ‘‹ğ‘–]=ğ‘›ğœ‡
Var[âˆ‘
ğ‘–=1
ğ‘›
ğ‘‹ğ‘–]=ğ‘›ğœ
2

[DescripciÃ³n de la imagen: un libro con una ecuaciÃ³n matemÃ¡tica en Ã©l | TranscripciÃ³n de la imagen: Suma de variables 1.1.d.

V.a. 1.1.d.con y]]

Suma de variables i.i.d.
v.a. i.i.d. con  y  
E [ ğ‘‹ğ‘›]=?
Var [ ğ‘‹ğ‘›]=?
ğ‘‹ğ‘›= 1
ğ‘›âˆ‘
ğ‘–=1
ğ‘›
ğ‘‹ğ‘–
Promedio
:

[DescripciÃ³n de la imagen: sum variables i d | TranscripciÃ³n de la imagen: Suma de variables 1.1.d.

V.a. 1.1.d.con y

Promedio Ãn=%2 X,
" 1=1

E X, =?]]

Suma de variables i.i.d.
v.a. i.i.d. con  y  
E [ ğ‘‹ğ‘›]=ğœ‡
Var [ ğ‘‹ğ‘›]= ğœ2
ğ‘›
ğ‘‹ğ‘›= 1
ğ‘›âˆ‘
ğ‘–=1
ğ‘›
ğ‘‹ğ‘–
Promedio
:

[DescripciÃ³n de la imagen: suma de variables i d | TranscripciÃ³n de la imagen: Suma de variables 1.1.d.

V.a. 1.1.d.con y

Promedio Ãn=%2 X,
" 1=1

EX =u]]

Suma de v.a. independientes
Casos especiales

[DescripciÃ³n de la imagen: un papel en blanco con el papel en blanco del papel del papel del papel del papel del papel del papel del papel del papel del papel del papel del papel del papel del papel del papel del papel del papel del papel del papel del papel del papel del papel del papel del papel del papel del papel del papel del papel del papel del papel del papel del papel del papel del papel del papel del papel del papel del papel del papel del papel del papel del papel del papel del papel del papel del]

Suma de v.a. independientes
Â¡Ojo!
â€¢
Esos eran casos especiales, 
no siempre se da
â€¢
No 
ejemplos: 
suma 
de 
uniformes, 
suma 
de 
exponenciales, etc.

[DescripciÃ³n de la imagen: una nota con las palabras 'snos' y 'snos']

Suma de v.a. independientes
Â¡Ojo!
â€¢
Un no-ejemplo de interÃ©s:
v.a. i.i.d., con 
âˆ‘
ğ‘–=1
ğ‘›
ğ‘‹ğ‘–
?

[DescripciÃ³n de la imagen: Un libro con las palabras | TranscripciÃ³n de la imagen: 1 ,>uma de v.a. independientes
Â¡Ojo!

* Un no-ejemplo de interÃ©s:

3

2

la V.a. 1.1.d., con
E

â€”< -

7]]

Suma de v.a. independientes
Â¡Ojo!
â€¢
Un no-ejemplo de interÃ©s:
v.a. i.i.d., con 
âˆ‘
ğ‘–=1
ğ‘›
ğ‘‹ğ‘–
Bino(ğ‘›,ğ‘)

[DescripciÃ³n de la imagen: un libro con un bolÃ­grafo y un bolÃ­grafo en Ã©l | TranscripciÃ³n de la imagen: 1 ,>uma de v.a. independientes
Â¡Ojo!

* Un no-ejemplo de interÃ©s:

3
2
la V.a. 1.1.d., con

f Z X Bino(n,p)]]

Suma de v.a. independientes
Â¡Ojo!
â€¢
Otro no-ejemplo de interÃ©s:
v.a. i.i.d., con 
ğ‘†ğ‘›=âˆ‘
ğ‘–=1
ğ‘›
ğ‘‹ğ‘–

[DescripciÃ³n de la imagen: una nota con las palabras en espaÃ±ol | TranscripciÃ³n de la imagen: 1 ,>uma de v.a. independientes
Â¡Ojo!

* Otro no-ejemplo de interÃ©s:

3

2

la V.a. 1.1.d., con
E

= = >.. X,
zÃ‘[d â€”=â€” 1]]

Suma de v.a. independientes
v.a. i.i.d., con 
 Tiempo hasta el -Ã©simo evento de un 
proceso de Poisson .
P (ğ‘†ğ‘›>ğ‘¡)=P ( ğ‘(ğ‘¡)<ğ‘›)=âˆ‘
ğ‘–=0
ğ‘›âˆ’1 (ğœ†ğ‘¡)
ğ‘–
ğ‘–! ğ‘’
âˆ’ğœ†ğ‘¡

[DescripciÃ³n de la imagen: una nota con las palabras de, de, de y de escrito en espaÃ±ol | TranscripciÃ³n de la imagen: 1 ,>uma de v.a. independientes

V.a. 1.1.d., con

Tiempo hasta el -Ã©simo evento de un
proceso de Polsson .

Ã P(Sn>t)=1Âº(N(Â¡:)<n)=nÃ­:1 â€”

1=0]]

Suma de v.a. independientes
v.a. i.i.d., con 
ğ‘†ğ‘›
Gamma(ğ‘›, ğœ†)
ğ‘“ğ‘†ğ‘›(ğ‘¡)= ğœ†( ğœ†ğ‘¡)ğ‘›âˆ’1 ğ‘’âˆ’ğœ†ğ‘¡
(ğ‘›âˆ’1)!
ğ‘¡>0

[DescripciÃ³n de la imagen: una nota con la ecuaciÃ³n de la ecuaciÃ³n | TranscripciÃ³n de la imagen: 1 ,>uma de v.a. independientes

V.a. |.1.d., con
Sr Gammal(72,4)

fot=22 â‚¬

- â€” nâ€”1)! L>0]]

Suma de v.a. independientes
ğ‘†ğ‘›Gamma(ğ‘›,1)

[DescripciÃ³n de la imagen: un grÃ¡fico grÃ¡fico con el mismo nÃºmero de los dos puntos]

Preguntas

[DescripciÃ³n de la imagen: un cuaderno con una cara sonriente y un bolÃ­grafo | TranscripciÃ³n de la imagen: U
D
-
e
=
O
V
| -
Q]]

Desigualdad de Markov
Sea  una v.a. que sÃ³lo toma 
valores no-negativos. Entonces
ğ‘ƒ( ğ‘‹â‰¥ğ›¼)â‰¤E[ ğ‘‹]
ğ›¼

[DescripciÃ³n de la imagen: destualidade markoo]

Desigualdad de Markov
Idea de la demostraciÃ³n para v.a. 
continua

[DescripciÃ³n de la imagen: desula de marco]

Desigualdad de Chebychev
Sea  una v.a. con  y . Entonces
ğ‘ƒ(Â¿ ğ‘‹âˆ’ğœ‡âˆ¨â‰¥ğœ€)â‰¤ğœ2
ğœ€2

[DescripciÃ³n de la imagen: desuad cheyve se nace con y enes]

Desigualdad de Chebychev
DemostraciÃ³n usando desigualdad 
de Markov

[DescripciÃ³n de la imagen: desuala de cheyve demora oasual de cheyve]

Desigualdad de Chebychev
Ejemplo 1: v.a. normal
ğ‘ƒ(Â¿ ğ‘‹âˆ’ğœ‡âˆ¨â‰¥ğ‘˜ğœ) â‰¤1
ğ‘˜2
Probabilid
ad
Cota
1
0.3173
1.0000
2
0.0455
0.2500
3
0.0027
0.1111
4
0.0001
0.0625

[DescripciÃ³n de la imagen: un cuadro con un nÃºmero de decimales y un cuadro con un nÃºmero de decimales | TranscripciÃ³n de la imagen: Desigualdad de Chebychev

Ejemplo 1: v.a. normal]]

Ejemplo 2: promedio
v.a. i.i.d. con  y  
ğ‘ƒ(Â¿ ğ‘‹ğ‘›âˆ’ğœ‡âˆ¨â‰¥ğœ€)â‰¤ğœ2
ğ‘›ğœ€2
E [ ğ‘‹ğ‘›]=ğœ‡
Var [ ğ‘‹ğ‘›]= ğœ2
ğ‘›
Desigualdad de Chebychev

[DescripciÃ³n de la imagen: una nota con las palabras'''' y'' | TranscripciÃ³n de la imagen: Desigualdad de Chebychev

Ejemplo 2: promedio

V.a. 1.1.d.con y

Var[Ãn]=%2]]

Ley DÃ©bil de los Grandes NÃºmer
lim
ğ‘›â†’âˆğ‘ƒ(Â¿ ğ‘‹ğ‘›âˆ’ğœ‡âˆ¨â‰¥ğœ€)=0
v.a. i.i.d. con  y . Luego, para todo  
Decimos que  converge a  en 
probabilidad

[DescripciÃ³n de la imagen: una nota con las palabras''y''en espaÃ±ol]

Ley DÃ©bil de los Grandes NÃºmer
Implicancia prÃ¡ctica:
Podemos 
estimar 
las 
probabilidades 
repitiendo 
experimentos independientes un 
gran nÃºmero de veces

[DescripciÃ³n de la imagen: una nota con las palabras en espaÃ±ol]

Ley DÃ©bil de los Grandes NÃºmer
Ejemplo en Octave
x = rand(1000,100);
pro = cumsum(x)./(1:1000)';
n = 1:1000;
figure(1)
plot(n,pro(:,1),n,pro(:,2),n,pro(:,3))
figure(2)
p = sum((abs(pro-0.5)>0.01)');
plot(n,p)

[DescripciÃ³n de la imagen: una nota con las palabras ejep oye]

Ley DÃ©bil de los Grandes NÃºmer
Promedio de valores de n variables  
aleatorias uniformes en (0,1), puede 
observarse 
la 
reducciÃ³n 
de 
la 
variabilidad al aumentar el nÃºmero de 
variables que se promedian

[DescripciÃ³n de la imagen: un grÃ¡fico grÃ¡fico con un grÃ¡fico de lÃ­nea y un grÃ¡fico de lÃ­nea]

Ley DÃ©bil de los Grandes NÃºmeros:
Jacob Bernoulli (1655-1705) en una estampilla suiza de 1994, 
creador de la ley de los grandes nÃºmeros
Observen el grÃ¡fico de la tendencia del promedio hacia la media y la nociÃ³n 
de convergencia en probabilidad del promedio hacia la media en el Ã¡ngulo 
superior izquierdo.

[DescripciÃ³n de la imagen: ley de los grandes nÃºmeros]

Ley DÃ©bil de los Grandes NÃºmer
Frecuencia relativa de que el promedio 
de valores de n variables aleatorias 
uniformes en (0,1) difiera de 0.5 en 
mas de 0.01 â€¦ decrece esa frecuencia 
con el nÃºmero de sumandos con que se 
calcula el promedio â€¦

[DescripciÃ³n de la imagen: un grÃ¡fico con un grÃ¡fico de lÃ­nea que muestra el nÃºmero de los nÃºmeros de los nÃºmeros]

Preguntas

[DescripciÃ³n de la imagen: un cuaderno con una cara sonriente y un bolÃ­grafo | TranscripciÃ³n de la imagen: U
D
-
e
=
O
V
| -
Q]]

Teorema Central del LÃ­mite
v.a. i.i.d. con , . Luego, para  
grande 
ğ‘‹ğ‘›
aprox N( ğœ‡, ğœ
âˆšğ‘›)
âˆ‘
ğ‘–=1
ğ‘›
ğ‘‹ğ‘–
aprox
N (ğ‘›ğœ‡,âˆšğ‘›ğœ)

[DescripciÃ³n de la imagen: una nota con las palabras '', '' y ' ' | TranscripciÃ³n de la imagen: Teorema Central del LÃ­mite

con , . Luego, para]]

Teorema Central del LÃ­mite
v.a. i.i.d. con , . Luego, para  grande 
ğ‘‹ğ‘›
aprox N( ğœ‡, ğœ
âˆšğ‘›)

[DescripciÃ³n de la imagen: una foto de un hombre con un dibujo de una casa | TranscripciÃ³n de la imagen: Teorema Central del LÃ­mite

v.a. 1.1.d. con, . Luego, para grande

-I- -I--.-- -----Ill-- I- |

.
*
Â»
â€œd
_2
â€”
-*
Â»
a
>
9
-*
_Â»]]

Teorema Central del LÃ­mite
v.a. i.i.d. con , . Luego, para  grande 
ğ‘‹ğ‘›
aprox N( ğœ‡, ğœ
âˆšğ‘›)
R=rand(100,1000);
M=mean(R);
MO=sort(M);I=(1:1000)/1000;
m=mean(MO);s=std(MO);
z=(MO-m)/s;Fz=normcdf(z);
plot(z,I,'ko',z,Fz,'r-')
plot(z,abs(I-Fz),'r-')
SuperposiciÃ³n de la distribuciÃ³n empÃ­rica de 1000 valores estandarizados 
de la media de 100 nÃºmeros aleatorios con distribuciÃ³n uniforme en (0,1) 
y la funciÃ³n de distribuciÃ³n normal  estÃ¡ndar. En cuadro aparte la 
distancia entre ambas (para este caso fue menor que 0.02).

[DescripciÃ³n de la imagen: un grÃ¡fico con una lÃ­nea de datos y una lÃ­nea de datos]

Teorema Central del LÃ­mite
ğ‘‹ğ‘–
U (0,1)
ğ‘‹ğ‘›
aprox N(0.5,
1
âˆš12ğ‘›)
ğ‘ƒ(Â¿ ğ‘‹ğ‘›âˆ’0.5âˆ¨â‰¥ğœ€)â‰ˆ2(1âˆ’Î¦( ğœ€âˆš12ğ‘›))
Ejemplo 1

[DescripciÃ³n de la imagen: una nota con la fÃ³rmula de la fÃ³rmula | TranscripciÃ³n de la imagen: Teorema Central del LÃ­mite

Ejemplo 1
> ; 7 (O,.1)

* PiX,-05v>e821-Ble/12n)

X, N 0.5,L)]]

Teorema Central del LÃ­mite
Ejemplo 1 en Octave
x = rand(1000,1000);
pro = cumsum(x)./(1:1000)';
n = 1:1000;
p = sum((abs(pro-0.5)>0.01)')/1000;
figure(1)
plot(n,p,n,2*(1-normcdf(0.01*sqrt(12*n))))
figure(2)
semilogy(n,p,n,2*(1-normcdf(0.01*sqrt(12*n))))
hold on
semilogy(n,1./(12*0.01^2*n))

[DescripciÃ³n de la imagen: una nota con las palabras lÃ­nea central | TranscripciÃ³n de la imagen: Teorema Central del LÃ­mite

Ejemplo 1 en Octave

x = rand(1000,1000);

pro = cumsum(x)./(1:1000)';

n = 1:1000,

p = sum( (abs(pro-0.5)>0.01)')/1006;

figure(1)
plot(n,p,n,2* (1-normcdf (0.01*sagrt(12*n))))
figure(?2)

semi Logy (n, p, n,2* (1-normcdf (0.01*sgrt(12*n))))
hold on

semi logy (n,1./(12*0.0112*n))]]

Teorema Central del LÃ­mite
Ejemplo 1 en Octave

[DescripciÃ³n de la imagen: un grÃ¡fico del nÃºmero de los dos tipos diferentes de los mismos nÃºmeros | TranscripciÃ³n de la imagen: â€” SiIMUul.
â€” normal

0 200 400 600 800 1000]]

Teorema Central del LÃ­mite
Ejemplo 1 en Octave

[DescripciÃ³n de la imagen: un grÃ¡fico con una curva y un grÃ¡fico de lÃ­nea | TranscripciÃ³n de la imagen: â€” SiIMui.

â€” normal
â€” Chebychev

0 200 400 600 800 1000]]

Teorema Central del LÃ­mite
, 
ğ‘†ğ‘›Bino(ğ‘›,ğ‘)
aprox N (ğ‘›ğ‘,âˆšğ‘›ğ‘(1âˆ’ğ‘))
Ejemplo 2

[DescripciÃ³n de la imagen: una nota con las palabras lÃ­mite central | TranscripciÃ³n de la imagen: Teorema Central del LÃ­mite

-
-
E

Ejemplo 2

1S, Bino(n,p) NIinp,/np(l1-p)

aprox]]

Teorema Central del LÃ­mite
Ejemplo 2 Octave
n = 1000; p = 0.3;
k = 0:n;
pe= binopdf(k,n,p);
pa= normcdf((k+0.5-n*p)/sqrt(n*p*(1-p)));
pa= pa-normcdf((k-0.5-n*p)/sqrt(n*p*(1-p)));
figure(1)
plot(k,pe,k,pa)
figure(2)
plot(k,abs(pe-pa))

[DescripciÃ³n de la imagen: una nota con las palabras 'erp ove ']

Teorema Central del LÃ­mite
Ejemplo 2 Octave

[DescripciÃ³n de la imagen: un grÃ¡fico del nÃºmero de los dos tipos diferentes del nÃºmero de los dos tipos del nÃºmero de | TranscripciÃ³n de la imagen: 0.03 , |
â€” bino
0.095 == normal

0.02

0.015

0.01

0.005

200 250 300 350 400]]

Teorema Central del LÃ­mite
Ejemplo 2 Octave

[DescripciÃ³n de la imagen: una parcela con un grÃ¡fico de lÃ­nea | TranscripciÃ³n de la imagen: 0.0002 |

0.00015

0.0001

5e-05

200 250 300 350 400]]

p=0.01:0.01:0.99;
for i=1:length(p)
for j=1:length(n)
P=binocdf(0:n(j),n(j),p(i));
m=n(j)*p(i);s=sqrt(n(j)*p(i)*(1-p(i)));
N=normcdf(0:n(j),m,s);
E(i,j)=max(abs(P-N));
end
end
plot(p',E,'linewidth',4)
legend('n=50','n=100','n=150','n=200')
AproximaciÃ³n normal de la binomial
MÃ¡xima diferencia entre 
los valores de la funciÃ³n 
de distribuciÃ³n binomial 
y 
la 
aproximaciÃ³n 
normal en funciÃ³n de p 
para varios valores de 
n. 
Puede 
observarse 
que 
en 
regiones 
intermedias de valores 
de 
p y 
para 
varios 
valores crecientes de n 
el error es menor que 
0.1.

[DescripciÃ³n de la imagen: aprimonale normale normale]

p=0.01:0.01:0.99;
for i=1:length(p)
for j=1:length(n)
P=binocdf(0:n(j),n(j),p(i));
m=n(j)*p(i);s=sqrt(n(j)*p(i)*(1-p(i)));
N=normcdf(0:n(j),m,s);
E(i,j)=max(abs(P-N));
end
end
plot(p',E,'linewidth',4)
legend('n=50','n=100','n=150','n=200')
AproximaciÃ³n normal de la binomial
MÃ¡xima diferencia entre 
los valores de la funciÃ³n 
de distribuciÃ³n binomial 
y 
la 
aproximaciÃ³n 
normal en funciÃ³n de p 
para varios valores de 
n. 
Puede 
observarse 
que 
en 
regiones 
intermedias de valores 
de 
p y 
para 
varios 
valores crecientes de n 
el error es menor que 
0.1.

[DescripciÃ³n de la imagen: aprimonale normale normale]

Teorema Central del LÃ­mite
, 
Ejemplo 3
ğ‘†ğ‘›aprox N (ğ‘›ğœ†, âˆšğ‘›ğœ†)

[DescripciÃ³n de la imagen: una nota con las palabras lÃ­mite central]

Teorema Central del LÃ­mite
Ejemplo 3

[DescripciÃ³n de la imagen: un grÃ¡fico con una curva y una curva | TranscripciÃ³n de la imagen: 0.1

0.08

0.06

0.04

0.02

10

â€” n=10
â€” normal

15

20]]

Teorema Central del LÃ­mite
Ejemplo 3

[DescripciÃ³n de la imagen: un grÃ¡fico con una curva y una lÃ­nea de la misma longitud | TranscripciÃ³n de la imagen: 0.06

0.05

0.04

0.03

0.02

0.01

20

30

40

50

60

â€” n=50
â€” normal

70

80]]

Teorema Central del LÃ­mite
Ejemplo 3

[DescripciÃ³n de la imagen: un grÃ¡fico con una curva y una curva | TranscripciÃ³n de la imagen: 0.05

â€” normal

0.04

0.03

0.02

0.01

60 80 100 120 140]]

Supongamos que se presentan n clientes y sea Sn el tiempo necesario para 
atenderlos. Sea Tk el tiempo de atenciÃ³n del cliente k con k entre 1 y n. 
Supongamos que las variables aleatorias Tk son independientes y claramente 
idÃ©nticamente distribuidas.  Se tiene: 
                 
E(Tk) = 100 1.5 = 150 ; 
 V(Mk) = 100 1^2= 100 
Teorema Central del LÃ­mite

[DescripciÃ³n de la imagen: una nota con las palabras terme enrall lite | TranscripciÃ³n de la imagen: % Teorema Central del LÃ­mite
-

10. Los tiempos de servicio para los clientes que llegan a una caja de un supermercado pueden
suponerse variables aleatorias independientes con un promedio de 1.5 minutos y una dispersiÃ³n
de 1 minuto.

a) Calcular la probabilidad aproximada de que pueda atender a 100 clientes en menos de 2
horas de tiempo total de servicio de esta caja.

b) Calcular el nÃºmero de clientes 7 tal que la probabilidad de dar servicio a todos en menos
de 2 horas sea aproximadamente ().1.

Supongamos que se presentan n clientes y sea S, el tiempo necesario para
atenderlos. Sea "T, el tiempo de atenciÃ³n del cliente k con k entre 1 y n.
Supongamos que las variables aleatorias T, son independientes y claramente
1dÃ©nticamente distribuidas. Se tiene:

E(Tk) = 100 1.5 = 150 ;
V(Mk) = 100 112= 100]]

Se desea calcular  p = P(S100   < 120). Se puede aproximar el valor de p usando el 
teorema central del lÃ­mite dado que puede suponerse que â€œn es grandeâ€, â€¦ Para ello 
es necesario conocer el valor esperado y la varianza de S100
Se tiene  E(S100) = 150  y     V(S100) = 100 ïƒ—1 = 100 ya que los tiempos por cliente 
son variables aleatorias independientes e idÃ©nticamente distribuidas.
ğ‘=ğ‘ƒ( ğ‘†1 00< 12 0) â‰ˆÎ¦ Â¿
Entonces usando el teorema central del lÃ­mite:
ğ‘â‰ˆÎ¦ (âˆ’3 )â‰ˆ0.00135
Teorema Central del LÃ­mite

[DescripciÃ³n de la imagen: una nota con las palabras centrale]

Se desea calcular n tal que  p = P(S n  < 120) = 0.1. Se puede aproximar el   cÃ¡lculo 
usando el teorema central del lÃ­mite suponiendo que â€œn es grandeâ€, â€¦ Para ello es 
necesario conocer el valor esperado y la varianza de Sn
Se tiene  E(Sn) = 1.50 n  y     V(Sn) = n ïƒ—1 = n  ya que los tiempos por cliente son 
variables aleatorias independientes e idÃ©nticamente distribuidas.
ğ‘ƒ( ğ‘†n< 12 0) â‰ˆÎ¦ Â¿
Entonces usando el teorema central del lÃ­mite:
(
 
Teorema Central del LÃ­mite

[DescripciÃ³n de la imagen: una nota con las palabras centrale]

Supongamos que se presentan n clientes y sea Sn el gasto realizado por los n 
clientes y  Mk lo gastado por el cliente k con k entre 1 y n. Supongamos que las 
variables aleatorias Mk 
 
 son independientes y claramente idÃ©nticamente 
distribuidas.  Se tiene: 
                 
m
70
140
210
P(Mk = m)
0.3
0.6
0.1
E(Mk) = (70 0.3 + 140 0.6 + 210 0.1) = 126 ; 
 V(Mk) = 17640- 126^2 = 1764 
Teorema Central del LÃ­mite

[DescripciÃ³n de la imagen: una tabla con una lista de elementos y nÃºmeros]

Se desea calcular  p = P(S100   > 13000). Se puede aproximar el valor de p usando el 
teorema central del lÃ­mite dado que puede suponerse que â€œn es grandeâ€, â€¦ Para ello 
es necesario conocer el valor esperado y la varianza de S100
Se tiene  E(S100) = 100 ïƒ—126 = 12600    y     V(S100) = 100 ïƒ—1764 = 176400 ya que 
los gastos por cliente son variables aleatorias independientes e idÃ©nticamente 
distribuidas.
ğ‘=ğ‘ƒ(ğ‘†100>13000)=1âˆ’ğ‘ƒ(ğ‘†100â‰¤13000)â‰ˆ1âˆ’Î¦Â¿
Entonces usando el teorema central del lÃ­mite:
ğ‘â‰ˆ1âˆ’Î¦ (0.9524 )=Î¦ (âˆ’0.9524 )â‰ˆ0.1705
Teorema Central del LÃ­mite

[DescripciÃ³n de la imagen: una nota con las palabras terme centrale]

Preguntas

[DescripciÃ³n de la imagen: un cuaderno con una cara sonriente y un bolÃ­grafo | TranscripciÃ³n de la imagen: U
D
-
e
=
O
V
| -
Q]]

