Primer Cuatrimestre 2025
Sistemas de 
Inteligencia Artificial
Perceptr√≥n 
Multicapa
Rodrigo Ramele
Eugenia Pi√±eiro
Alan Pierri
Santiago Reyes
Marina Fuster
Luciano Bianchi
Marco Scilipoti
Paula Oseroff
Joaqu√≠n Girod

[Descripci√≥n de la imagen: una imagen en blanco y negro de un patr√≥n colorido, abstracto, fraly, fra - como]

RESUMEN DE LA CLASE ANTERIOR
‚óè
¬øQui√©nes son McCulloch y Pitts? ¬øCu√°l fue su aporte?
‚óè
¬øQu√© tipo de problemas podemos resolver con el perceptr√≥n 
simple escal√≥n?
‚óè
¬øCon qu√© mecanismo encuentro los pesos sin√°pticos y el bias?
‚óè
¬øQu√© tipo de problemas puedo resolver al cambiar la funci√≥n de 
activaci√≥n? Por ejemplo: por una lineal o no lineal de la familia 
de sigmoideas.

[Descripci√≥n de la imagen: resr de la astero ques de la astero ques de la astero]

LIMITACIONES DEL PERCEPTR√ìN SIMPLE
1
2
1

[Descripci√≥n de la imagen: un dibujo en l√≠nea de forma rectangular]

BUSCANDO ALTERNATIVAS‚Ä¶

[Descripci√≥n de la imagen: un diagrama de una bola y una bola con una l√≠nea de simetr√≠a | Transcripci√≥n de la imagen: BUSCANDO ALTERNATIVAS... I !

‚Äî 1
√çj‚Äî 9(X) _ 1+exp_28'r
b

Im = (0, 1)]]

BUSCANDO ALTERNATIVAS‚Ä¶
1000
-1000
-2000
1000
-1
1

[Descripci√≥n de la imagen: un diagrama de un autob√∫s con una luz roja | Transcripci√≥n de la imagen: BUSCANDO ALTERNATIVAS...

1 B=1
1000
xf
-100
b
1
1 2
o(h)=h
1 -1
B=1
y, ‚Äî 1000]]

¬øC√ìMO PUEDO COMBINAR LOS PERCEPTRONES?

[Descripci√≥n de la imagen: un fondo blanco con las palabras 'como como' y 'como']

¬øQu√© clase de problemas 
puedo representar?

[Descripci√≥n de la imagen: Que que que que que que que que que que que que que que que que que que que que]

TEOREMA DE APROXIMACI√ìN UNIVERSAL 
1989 - Cybenko, G.
(expansi√≥n en 1990, Hornik, K.)

[Descripci√≥n de la imagen: un gr√°fico con dos im√°genes de un hombre y una mujer]

TEOREMA DE APROXIMACI√ìN UNIVERSAL 
1989 - Cybenko, G.
(expansi√≥n en 1990, Hornik, K.)

[Descripci√≥n de la imagen: un gr√°fico gr√°fico con un gr√°fico gr√°fico y un gr√°fico gr√°fico]

TEOREMA DE APROXIMACI√ìN UNIVERSAL 
1989 - Cybenko, G.
(expansi√≥n en 1991, Hornik, K.)

[Descripci√≥n de la imagen: un texto que dice,'tgemaxiom universal ' | Transcripci√≥n de la imagen: TEOREMA DE APROXIMACI√ìN UNIVERSAL g|
1989 - Cybenko, G.

(expansi√≥n en 1991, Hornik, K.)

While the approximating properties we have described are quite powerful, we
have focused only on existence. The important questions that remain to be answered
deal with feasibility, namely how many terms in the summation (or equivalently,
how many neural nodes) are required to yield an approximation of √° given quality?
What properties of the function being approximated play a role in determining the
number of terms? At this point, we can only say that we suspect quite strongly that
the overwhelming majority of approximation problems will require astronomical
numbers of terms. This feeling is based on the curse of dimensionality that plagues
multidimensional approximation theory and statistics. Some recent progress con-]]

PERCEPTR√ìN MULTICAPA

[Descripci√≥n de la imagen: un diagrama de un √°rbol con algunos puntos | Transcripci√≥n de la imagen: M = cantidad capas

PERCEPTR√ìN MULTICAPA]]

¬øC√ìMO CALCULAMOS LA SALIDA DE LA RED? FEED-FORWARD PASS

[Descripci√≥n de la imagen: un diagrama de un √°rbol con los nombres de cada uno de los nombres]

Salida de la neurona:
Salida de la neurona de una capa intermedia:
Salida de la neurona de la primera capa intermedia:
¬øC√ìMO CALCULAMOS LA SALIDA DE LA RED? FEED-FORWARD PASS

[Descripci√≥n de la imagen: una imagen de una pantalla de ordenador con las palabras '','''' y'' | Transcripci√≥n de la imagen: ¬øC√ìMO CALCULAMOS LA SALIDA DE LA RED? FEED-FORWARD PASS

Salida de la neurona:

= T V . W)
Salida de la neurona de una capa intermedia:

m‚Äî1 m
= M =1

Salida de la neurona de la primera capa intermedia:

] 1
= 0(X x .w.)
k=1 ,]]

¬øC√ìMO CALCULAMOS LA SALIDA DE LA RED? FEED-FORWARD PASS

[Descripci√≥n de la imagen: un diagrama de un √°rbol con algunos puntos]

¬øC√ìMO VA 
CAMBIANDO EL 
ALGORITMO?

[Descripci√≥n de la imagen: una pantalla blanca con las palabras 'como' y 'como' | Transcripci√≥n de la imagen: Initialize multi layer perceptron architecture ¬øC√ìMO VA

Initialize weights w to small random values

set learning rate n CAMBIAN DO EL
for a fixed number of epochs: ALGORITMO?

For each training example p in the dataset:
1. Compute activation given by feed forward pass:
_ M-1 M
O; = G(Z'K]Vk 'W¬°k)'
where j is the index of output neuron,
M is the index of output layer,
k is the index of neuron from previous layer.

sum is over the gty. of neurons from the previous layer.

2. Update the weights and bias:

ece

3. Calculate perceptron error:
erFrOL = EE X) , X)

convergence = True if error < e else False

if convergence: break

End]]

AHORA‚Ä¶ ¬øC√ìMO LO ENTRENAMOS? üëÄ

[Descripci√≥n de la imagen: un diagrama de un √°rbol con un n√∫mero de puntos | Transcripci√≥n de la imagen: AHORA... ¬øC√ìMO LO ENTRENAMOS? * *]]

AHORA‚Ä¶ ¬øC√ìMO LO ENTRENAMOS? üëÄ
Recordemos‚Ä¶

[Descripci√≥n de la imagen: un diagrama de un √°rbol con un n√∫mero de nodos | Transcripci√≥n de la imagen: AHORA.... ¬øC√ìMO LO ENTRENAMOS? ‚Ç¨ %]]

AHORA‚Ä¶ ¬øC√ìMO LO ENTRENAMOS? üëÄ
Recordemos‚Ä¶

[Descripci√≥n de la imagen: un diagrama de un √°rbol con un c√≠rculo verde | Transcripci√≥n de la imagen: AHORA.... ¬øC√ìMO LO ENTRENAMOS? ‚Ç¨ %]]

0.1
-3.4
2
0.6
0.34
-1.2
-0.01
0.86
-1.9
-2.3
0.7
0.02
‚Ä¶
ENTRENAMIENTO: EXPLICACI√ìN CONCEPTUAL

[Descripci√≥n de la imagen: un diagrama de un plano con un plano en el medio y un plano en el medio | Transcripci√≥n de la imagen: ENTRENAMIENTO: EXPLICACI√ìN CONCEPTUAL]]

ENTRENAMIENTO: EXPLICACI√ìN CONCEPTUAL
Mecanismo de optimizaci√≥n: 
por ahora, gradiente 
descendente.
Regla de la cadena de la 
derivada para capas ocultas

[Descripci√≥n de la imagen: una imagen de un circuito con las palabras en espa√±ol]

√çndice
Descripci√≥n
i
√≠ndice de la neurona de la capa de salida (o siguiente)
j
√≠ndice de la neurona de la capa intermedia
k
√≠ndice de la neurona de entrada o de la capa anterior
m
√≠ndice de la capa intermedia
p
cantidad datos
ùúá
dato en particular

[Descripci√≥n de la imagen: un diagrama de un √°rbol con un n√∫mero de nodos]

ENTRENAMIENTO: EXPLICACI√ìN CONCEPTUAL
‚ùì

[Descripci√≥n de la imagen: un ejemplo del inter - exor con | Transcripci√≥n de la imagen: ENTRENAMIENTO: EXPLICACI√ìN CONCEPTUAL

w w√≠ Wi
O Ds O s √ìME]]

‚ùì
Aplicamos la regla de la cadena:
ENTRENAMIENTO: EXPLICACI√ìN CONCEPTUAL

[Descripci√≥n de la imagen: un ejemplo del algoritmo para el algoritmo | Transcripci√≥n de la imagen: ENTRENAMIENTO: EXPLICACI√ìN CONCEPTUAL

)) ‚Äî )‚Äî C) =1

Aplicamos la regla de la cadena:

dE aE 90, AN

6W11 601 6h1 (3W11]]

‚ùì
ENTRENAMIENTO: EXPLICACI√ìN CONCEPTUAL

[Descripci√≥n de la imagen: un circuito con un circuito y un circuito con un circuito | Transcripci√≥n de la imagen: ENTRENAMIENTO: EXPLICACI√ìN CONCEPTUAL

w w√≠ Wi
O O u O u √ìME]]

‚ùì
Aplicamos la regla de la cadena:
ENTRENAMIENTO: EXPLICACI√ìN CONCEPTUAL

[Descripci√≥n de la imagen: un ejemplo del algoritmo para el algoritmo]

‚ùì
ENTRENAMIENTO: EXPLICACI√ìN CONCEPTUAL

[Descripci√≥n de la imagen: un circuito con un circuito y un circuito con un circuito | Transcripci√≥n de la imagen: ENTRENAMIENTO: EXPLICACI√ìN CONCEPTUAL

w w√≠ Wi
O O O √ìME]]

‚ùì
Aplicamos la regla de la cadena:
ENTRENAMIENTO: EXPLICACI√ìN CONCEPTUAL

[Descripci√≥n de la imagen: un ejemplo del algoritmo para el algoritmo | Transcripci√≥n de la imagen: ENTRENAMIENTO: EXPLICACI√ìN CONCEPTUAL

w w√≠ *
O O O √ìME

Aplicamos la regla de la cadena:

aE ‚Äî 0E 0, √ìh, 3V, h

w 90, √≥h av√ç √≥h

11]]

RUMELHART, HINTON, WILLIAMS (1986)
‚óè
Trabajan en un nuevo 
algoritmo para actualizar los 
pesos de una red neuronal 
usando retropropagaci√≥n 
(backpropagation)
‚óè
Para calcular la 
actualizaci√≥n de los pesos 
utilizaremos el algoritmo del 
gradiente descendente y la 
regla de la cadena para la 
diferenciaci√≥n.
0.1
-3.4
2
0.6
0.34
-1.2
-0.01
0.86
-1.9
-2.3
0.7
0.02
‚Ä¶

[Descripci√≥n de la imagen: rehart, william william, william, y william]

DELTA: EXPLICACI√ìN CONCEPTUAL
‚ùì
Aplicamos la regla de la cadena:

[Descripci√≥n de la imagen: un diagrama del circuito bidimensional | Transcripci√≥n de la imagen: DELTA: EXPLICACI√ìN CONCEPTUAL]]

DELTA: EXPLICACI√ìN CONCEPTUAL
‚ùì
Aplicamos la regla de la cadena:

[Descripci√≥n de la imagen: del exicio capital | Transcripci√≥n de la imagen: DELTA: EXPLICACI√ìN CONCEPTUAL]]

DELTA: EXPLICACI√ìN CONCEPTUAL
‚ùì
Aplicamos la regla de la cadena:

[Descripci√≥n de la imagen: del exicio capital | Transcripci√≥n de la imagen: DELTA: EXPLICACI√ìN CONCEPTUAL

1 2 W
Wa W√≠y 11
E) () ‚Äî(7)‚Äî9) 1=10

Aplicamos la regla de la cadena:]]

¬øC√ìMO VA 
CAMBIANDO EL 
ALGORITMO?

[Descripci√≥n de la imagen: una pantalla blanca con un texto rojo que lee,'comoo alorto???? | Transcripci√≥n de la imagen: Initialize multi layer perceptron architecture ¬øC√ìMO VA

Initialize weights w to small random values

set learning rate n CAMBIAN DO EL
for a fixed number of epochs: ALGORITMO?

For each training example p in the dataset:

1. Compute activation given by feed forward pass:
M-1 M
0, = e<%vk 'ij)'

where j is the index of output neuroan,
M is the index of output layer,
k is the index of neuron from previous layer.

sum is over the gty. of neurons from the previous layer.

2. Update the weights and bias:
optimizer (GD) with chain rule
for inner layers (calculated using back-propagation)

3. Calculate perceptron error:
error. = C E <e7 X)
convergence = True if error < e else False

if convergence: break

End]]

¬øPOR QU√â FUE TAN IMPORTANTE?
‚óè
Permite resolver el problema de determinar cu√°nto 
contribuye cada neurona al error del perceptr√≥n 
multicapa de manera eficiente.
‚óè
Herramienta pr√°ctica para aportar evidencia emp√≠rica al 
Teorema de Aproximaci√≥n Universal
‚óè
Renueva el inter√©s en el √°rea de inteligencia artificial
‚óè
El concepto de entrenar redes ‚Äúdeep‚Äù se hace posible 
con back propagation

[Descripci√≥n de la imagen: una imagen de una persona con una cara y un t√≠tulo]

[Descripci√≥n de la imagen: una taza de caf√© y dos galletas en una tabla de madera]

PERCEPTR√ìN SIMPLE
PERCEPTR√ìN MULTICAPA
Proceso para 
obtener la salida 
de la neurona 
(‚Äúpredecir‚Äù)
Proceso de 
‚Äúaprendizaje‚Äù 
para ajustar los 
pesos
?
?
?
Funci√≥n de costo 
(medir error con 
respecto a la 
salida esperada)

[Descripci√≥n de la imagen: perspilel perspilel perspilel]

PERCEPTR√ìN SIMPLE
PERCEPTR√ìN MULTICAPA
Proceso para 
obtener la salida 
de la neurona 
(‚Äúpredecir‚Äù)
Proceso de 
‚Äúaprendizaje‚Äù 
para ajustar los 
pesos
Funci√≥n de costo 
(medir error con 
respecto a la 
salida esperada)
?
?

[Descripci√≥n de la imagen: perspilel perspilel perspilel perspilel perspilel perspilel perspilel perspilel perspilel perspilel perspilel perspilel perspilel perspilel perspilel perspilel perspilel perspilel perspilel perspilel perspilel perspilel perspilel perspilel pers | Transcripci√≥n de la imagen: PERCEPTR√ìN SIMPLE PERCEPTR√ìN MULTICAPA

Proceso para E ‚Äî m‚Äî1 de
obtener la salida Vj 9( ? Vk - ij)
de la neurona k=1

(‚Äúpredecir‚Äù) m = 1..M (0.= V√≠", 5= V?)

Funci√≥n de costo
(medir error con
respecto a la
salida esperada)

?

A2
E(0) =7ZO(C ‚Äî0)
|_1=

nuevo anterior

Proceso de = w + Aw
‚Äúaprendizaje‚Äù t?
para ajustar los w = - 0E L

pesos T ow]]

PERCEPTR√ìN SIMPLE
PERCEPTR√ìN MULTICAPA
Proceso para 
obtener la salida 
de la neurona 
(‚Äúpredecir‚Äù)
Proceso de 
‚Äúaprendizaje‚Äù 
para ajustar los 
pesos
?
Funci√≥n de costo 
(medir error con 
respecto a la 
salida esperada)

[Descripci√≥n de la imagen: perspilel perspilel perspilel perspilel perspilel perspilel perspilel perspilel perspilel perspilel perspilel perspilel perspilel perspilel perspilel perspilel perspilel perspilel perspilel perspilel perspilel perspilel perspilel perspilel pers | Transcripci√≥n de la imagen: PERCEPTR√ìN SIMPLE PERCEPTR√ìN MULTICAPA

Proceso para
obtener la salida
de la neurona
(‚Äúpredecir‚Äù)

m‚Äî1 m

m
= e(k;1 ; .)

m=1..M (0,=V",x =V1)

Funci√≥n de costo
(medir error con
respecto a la
salida esperada)

2

p-1
E(0) =+ 0 -05 E(0) =I -01)
h=0 hi

nuevo anterior
Proceso de 177 = W + Aw
‚Äúaprendizaje‚Äù ?
para ajustar los Ae ‚Äî 0E L
pesos _ u w]]

RETROPROPAGACI√ìN: NOTACI√ìN
√çndice
Descripci√≥n
i
√≠ndice de la neurona de la capa de salida (o siguiente)
j
√≠ndice de la neurona de la capa intermedia
k
√≠ndice de la neurona de entrada o de la capa anterior
m
√≠ndice de la capa intermedia
p
cantidad datos
ùúá
dato en particular

[Descripci√≥n de la imagen: propo de propo propo propo propo propo propo propo propo propo propo propo propo propo propo propo propo propo propo propo propo propo propo propo propo propo propo]

RETROPROPAGACI√ìN: CAPA DE SALIDA (j = M)
Notar que el ejemplo est√° hecho para un dato de entrada. Se deber√° extender al conjunto.

[Descripci√≥n de la imagen: un diagrama del modelo topol√≥gico para el modelo topol√≥gico | Transcripci√≥n de la imagen: E(0) = -E C- 0?>2
RETROPROPAGACI√ìN: CAPA DE SALIDA ( = M) 0= e(hi)

h =X V√≠_"'1 .W

j=1 7

w= - dE ‚Äî dE %
W = Maw | ‚Äî _‚Äî‚Äù¬ª aw ‚Äî 00, 0h AW.

Notar que el ejemplo est√° hecho para un dato de entrada. Se deber√° extender al conjunto.]]

RETROPROPAGACI√ìN: CAPA DE SALIDA (j = M)
Notar que el ejemplo est√° hecho para un dato de entrada. Se deber√° extender al conjunto.

[Descripci√≥n de la imagen: un diagrama del algoritmo para el algoritmo | Transcripci√≥n de la imagen: E(0) = -E C- 0?>2
RETROPROPAGACI√ìN: CAPA DE SALIDA ( = M) 0= e(hi)

h=y "".w

E E ECAO
W = MNy | ‚Äî ‚Äî oW, ‚Äî 90| an

1

ij

= 6- 0)- 1e017

y

Notar que el ejemplo est√° hecho para un dato de entrada. Se deber√° extender al conjunto.]]

RETROPROPAGACI√ìN: CAPA DE SALIDA (j = M)
Notar que el ejemplo est√° hecho para un dato de entrada. Se deber√° extender al conjunto.

[Descripci√≥n de la imagen: un diagrama del algoritmo para el algoritmo | Transcripci√≥n de la imagen: E(0) = -E C- 0?>2
RETROPROPAGACI√ìN: CAPA DE SALIDA ( = M) 0= e(hi)

h=y "".w

E E ECAO
W = MNy | ‚Äî ‚Äî oW, ‚Äî 90| an

ij

0E ‚Äî = ' M‚Äî-1
= 6- 99 DEGY,

0E M-1 ,
w = ‚Äî 6¬°V¬° 6¬° = (Z¬° ‚Äî O¬°)9 (h¬°)

Notar que el ejemplo est√° hecho para un dato de entrada. Se deber√° extender al conjunto.]]

RETROPROPAGACI√ìN: CAPA DE SALIDA (j = M)
Notar que el ejemplo est√° hecho para un dato de entrada. Se deber√° extender al conjunto.

[Descripci√≥n de la imagen: un diagrama del modelo topol√≥gico para el modelo topol√≥gico | Transcripci√≥n de la imagen: E(0) = -E C- 0?>2
RETROPROPAGACI√ìN: CAPA DE SALIDA ( = M) 0= e(hi)

h=y "".w

E E ECAO
W = MNy | ‚Äî ‚Äî oW, ‚Äî 90| an

ij

dE _ _ ' M-1
a= 6- 976 96)OY)
0E M-1 ,
6W¬°¬° ‚Äî 6iVj 6¬° ‚Äî (¬ø¬° _ 0¬°)9 (h¬°)
‚Äî1
AW¬°¬° = T]5¬°V

Notar que el ejemplo est√° hecho para un dato de entrada. Se deber√° extender al conjunto.]]

RETROPROPAGACI√ìN: CAPA DE SALIDA (j = M)
Notar que el ejemplo est√° hecho para un dato de entrada. Se deber√° extender al conjunto.

[Descripci√≥n de la imagen: un diagrama del modelo topol√≥gico para el modelo topol√≥gico | Transcripci√≥n de la imagen: 2
E(0) =>IE C ‚Äî 05)
hi

RETROPROPAGACI√ìN: CAPA DE SALIDA ( = M) 0,= O(h)
h 'El V√≠_"'1 W

E E ECAO
W = MNy | ‚Äî ‚Äî oW, ‚Äî 90| an

ij

dE _ _ ; M-1
a= 6- 976 96)OY)
0E M-1 ,
6W¬°¬° ‚Äî 6iVj 6¬° ‚Äî (¬ø¬° _ 0¬°)9 (h¬°)
‚Äî1
AW¬°¬° = T]5¬°V

Notar que el ejemplo est√° hecho para un dato de entrada. Se deber√° extender al conjunto.]]

RETROPROPAGACI√ìN: CAPA OCULTA (j = M-1 , j in [M-1, ‚Ä¶, 1])
Notar que el ejemplo est√° hecho para un dato de entrada. Se deber√° extender al conjunto.

[Descripci√≥n de la imagen: un diagrama de un modelo topol√≥gico]

Notar que el ejemplo est√° hecho para un dato de entrada. Se deber√° extender al conjunto.
RETROPROPAGACI√ìN: CAPA OCULTA (j = M-1 , j in [M-1, ‚Ä¶, 1])

[Descripci√≥n de la imagen: un diagrama del modelo topol√≥gico para el cuatroier | Transcripci√≥n de la imagen: 2
E(0) =>IE C ‚Äî 05)
hi

RETROPROPAGACI√ìN: CAPA OCULTA ( = M-1 , jin [M-1; ..., 1)) 0,= e(h)
h 'El V√≠_"'1 .W,

JE aE aE 90 √ìh | av aR

= - Maw| ‚Äî q - [a0 an 9 r

jk j jk
√≥E ; m m
E =- )X C- 9)0em630W, M "
√ìW_ √≥ l 1 1 y a, M m
jk l √≥h¬°' √ìij

Notar que el ejemplo est√° hecho para un dato de entrada. Se deber√° extender al conjunto.]]

Notar que el ejemplo est√° hecho para un dato de entrada. Se deber√° extender al conjunto.
RETROPROPAGACI√ìN: CAPA OCULTA (j = M-1 , j in [M-1, ‚Ä¶, 1])

[Descripci√≥n de la imagen: un diagrama de la propagaci√≥n de la propagaci√≥n de la propagaci√≥n de la propagaci√≥n de la propagaci√≥n de la propagaci√≥n de | Transcripci√≥n de la imagen: RETROPROPAGACI√ìN: CAPA OCULTA (j = M-1 , jin [M-1) ..., 1)

m m
w ‚Äî TE
w | ‚Äî awr - 90 (ah (ay an a

E =- )X ‚Ç¨ - 9)em30)W, 7 *

m m

‚Äú
j l ‚Äî‚Äî‚Äî‚Äî.y‚Äî‚Äî 6h¬°. √≥w¬°k
√ì.
i
m m
=. E ‚Äî
a m l l] a 08 , m
Wi, ; √ìh. √≥w,
J j jk

Notar que el ejemplo est√° hecho para un dato de entrada. Se deber√° extender al conjunto.]]

Notar que el ejemplo est√° hecho para un dato de entrada. Se deber√° extender al conjunto.
RETROPROPAGACI√ìN: CAPA OCULTA (j = M-1 , j in [M-1, ‚Ä¶, 1])

[Descripci√≥n de la imagen: un diagrama de la propagaci√≥n de la propagaci√≥n de la propagaci√≥n de la propagaci√≥n de la propagaci√≥n de la propagaci√≥n de | Transcripci√≥n de la imagen: m m
= e(1")

m
‚Äî oe 0 √ìN V AN
90 √ìh ay a aw
j jk
0E
m ‚Äî
√≥wjk
dE m m‚Äî1
= - 29W, 0( )01) V
W¬°'k a J k

Notar que el ejemplo est√° hecho para un dato de entrada. Se deber√° extender al conjunto.]]

RETROPROPAGACI√ìN: CAPA OCULTA (j = M-1 , j in [M-1, ‚Ä¶, 1])

[Descripci√≥n de la imagen: el diagrama muestra las tres fases del modelo propuesto | Transcripci√≥n de la imagen: RETROPROPAGACI√ìN: CAPA OCULTA (j = M-1 , jin [M-1) ..., 1) =y

0E m m‚Äîi
E - -‚Äîy8W ¬£
u le ray 0 I 7
87'Il
j
m,,mn‚Äî1
Aw = 16.V

j k]]

RETROPROPAGACI√ìN: CAPA OCULTA (j = M-1 , j in [M-1, ‚Ä¶, 1])

[Descripci√≥n de la imagen: el diagrama muestra las tres fases del modelo propuesto | Transcripci√≥n de la imagen: RETROPROPAGACI√ìN: CAPA OCULTA (j = M-1 , jin [M-1) ..., 1) EA]]

Notar que el ejemplo est√° hecho para un dato de entrada. Se deber√° extender al conjunto.
RETROPROPAGACI√ìN: CAPA OCULTA (j in [M-1, ‚Ä¶, 1])

[Descripci√≥n de la imagen: un diagrama de la propagaci√≥n de la propagaci√≥n de la propagaci√≥n de la propagaci√≥n de la propagaci√≥n de la propagaci√≥n de]

PERCEPTR√ìN SIMPLE
PERCEPTR√ìN MULTICAPA
Proceso para 
obtener la salida 
de la neurona 
(‚Äúpredecir‚Äù)
Proceso de 
‚Äúaprendizaje‚Äù 
para ajustar los 
pesos
Funci√≥n de costo 
(medir error con 
respecto a la 
salida esperada)

[Descripci√≥n de la imagen: perspile perspile multila | Transcripci√≥n de la imagen: PERCEPTR√ìN SIMPLE PERCEPTR√ìN MULTICAPA

m‚Äî1

= (E V w

j

Proceso para
obtener la salida
de la neurona

(*predecir‚Äù) m=1..M (0=V, x =V)

Funci√≥n de costo i p‚Äî-1 2 1 " T

(medi ‚Äî H h ‚Äî ! ‚Äî

de E(0) =+ 3 ( -0"  E(0) =0 -0)
h=0 hi

salida esperada)

Proceso de Wnuevo ‚Äî Wanterzor + Aw AW¬°¬° ‚Äî n6¬°V]. 6¬° "- (¬ø¬° _ ¬∫,-)¬∫'(h,)
‚Äúaprendizaje‚Äù

para ajustar los ‚Äî dE _

pesos AwW = - , AW;,,;( = n8;,nV;(n - = -C 877 w e'(h")]]

¬øC√ìMO VA 
CAMBIANDO EL 
ALGORITMO?
TIP: expresar todo de 
manera matricial 
utilizando alguna 
librer√≠a como numpy.

[Descripci√≥n de la imagen: comoo algro | Transcripci√≥n de la imagen: Initialize multi layer perceptron architecture . C√ìMO VA
Initialize weights w to small random values ¬ø¬°

CAMBIANDO EL
for a fixed number of epochs: ALGORITMO?

For each training example p in the dataset:

4

Compute activation given by feed forward pass:
M1 ‚Äî M
0; = 9(%EQ .uv‚Äú,

where j is the index of output neuroan,
M is the index of output layer,

TIP: expresar todo de

k is the index of neuron from previous layer. l
sum is over the gty. of neurons from the previous layer. manera matrlC|a

utilizando alguna
Update the weights and bias: librer√≠a como numpy.

For each weight w.,:

1e

(gradient descendent)

, dE
W: = W: + AWw,, where Aw;: = ‚Äîn√≥√≠

0E a o ] 'alacta 1n
and e 15 computed using backpropagation

3. Calculate perceptron error:
error ‚Äî ¬£ X) ..7 X)

convergence = True if error < e else False

if convergence: break]]

[Descripci√≥n de la imagen: una taza de caf√© y dos galletas en una tabla de madera]

INCREMENTAL/ONLINE
(Gradiente Descendente 
Estoc√°stico)
MINI LOTE/MINI BATCH
(Gradiente Descendente 
Estoc√°stico)
LOTE/BATCH
(Gradiente Descendente)
La actualizaci√≥n de los pesos de 
la red se hace luego de calcular el 
Œîw para un elemento del 
conjunto de datos
La actualizaci√≥n de los pesos de 
la red se hace luego de calcular el 
Œîw para un subconjunto de 
elementos del conjunto de datos
La actualizaci√≥n de los pesos de 
la red se hace luego de calcular el 
Œîw para todos los elementos 
del conjunto de datos

[Descripci√≥n de la imagen: una tabla con tres tipos diferentes de la palabra]

¬øC√ìMO VA 
CAMBIANDO EL 
ALGORITMO?
VERSI√ìN BATCH
TIP: expresar todo de 
manera matricial 
utilizando alguna 
librer√≠a como numpy.

[Descripci√≥n de la imagen: comoo algritoo varia | Transcripci√≥n de la imagen: Initialize multi layer perceptron architecture . C√ìMO V¬∫

Initialize weights w to small random values
p CAMBIANDO EL
‚Äî ALGORITMO?
Aws = 0 "

For each training example h in the dataset: VE RSI√ìN BATCH

1. Compute activation given by feed forward pass:

H
(1)

for a fixed number 0

N M
o = 9(2Vk 'W]‚Äî'-)'

where j is the index of output neuron,
M is the index of output layer, TIP: expresar todo de

k is the index of neuron from previous layer. 1A
‚Äî ' E E manera matricial
sum is over the gty. of neurons from the previous layer.

utilizando alguna
librer√≠a como numpy.

2. Calculate the weights and bias:
For each weight w.:

E ‚Äú . ,
Aws = Aws + Aw,, where Aw, = ‚Äîn¬ø√≠ (gradient descendent)

dE

= is computed using backpropagation

and

W=W + Aws
Calculate perceptron error:
error = EC X) ..7 X)
convergence = True if error < e else False

if convergence: break

End]]

‚óè
¬øCu√°l es el costo de cada √©poca? (aprendizaje) 
‚óè
¬øCu√°les son los requerimientos de memoria?
‚óè
¬øC√≥mo manejan el ‚Äúruido‚Äù? (ejemplo, outliers)
‚óè
¬øCu√°nto tarda en converger?
‚óè
‚Ä¶
ESTRATEGIAS DE ENTRENAMIENTO: ONLINE / BATCH

[Descripci√≥n de la imagen: estica entreo / onde / lote]

EJERCICIO

[Descripci√≥n de la imagen: una pantalla blanca con un texto negro que lee,'' ' | Transcripci√≥n de la imagen: Initialize
Initialize

multi layer perceptron architecture
weights w to small random values

set learning rate n

for a fixed number of epochs:

End

For each training example p in the dataset:

Compute activation given by feed forward pass:
M-1 M
0; = 6(%Vk W.)-

where j is the index of output neuroan,
M is the index of output layer,

k is the index of neuron from previous layer.

sum is over the gty. of neurons from the previous layer.

. Update the weights and bias:

For each weight w,:

W: = W: + Aw,, where Aw: = ‚Äînj%% (gradient descendent)

E ‚Äî : 6
and ¬°¬£T is computed using backpropagation

Calculate perceptron error:

error ‚Äî ¬£ X) ..7 X)

convergence = True if error < e else False
if convergence: break

EJERCICIO]]

RESUMEN
‚óè
El perceptr√≥n multicapa me permite modelar 
transformaciones complejas. En teor√≠a, cualquier funci√≥n 
continua puede modelarse con un perceptr√≥n multicapa.
‚óè
La arquitectura del percept≈ïon multicapa debe realizarse 
manualmente. A priori, no tenemos una receta que nos 
permita definir ‚Äúla mejor arquitectura‚Äù.
‚óè
Retropropagaci√≥n provee un mecanismo con ciertas 
optimizaciones para definir el ‚Äúerror‚Äù en las capas ocultas 
y hallar las actualizaciones de los pesos que nos permiten 
minimizar la funci√≥n de costo.

[Descripci√≥n de la imagen: remen e perriza e perriza e perriza e perriza e perriza e perriza e perriza e perriza e perriza e perriza e perriza e perriza e perriza e perriza]

¬øQu√© estoy 
optimizando 
cuando quiero 
usar una red 
neuronal?

[Descripci√≥n de la imagen: una captura de pantalla de un ordenador con el texto, est est est est est est est est est est | Transcripci√≥n de la imagen: ¬øQu√© estoy
optimizando
cuando quiero
usar una red
neuronal?

Funci√≥n objetivo

)52¬£1n FO F R = 10 .. (3)
gi(X) <=0 (4)
h(7) =0 (5)

o Optimizaci√≥n Discreta: Programaci√≥n entera y
combinatoria

o Optimizaci√≥n Discreta: Ecuaci√≥n diof√°ntica

o Optimizaci√≥n Lineal: Programaci√≥n Lineal

o Optimizaci√≥n No Lineal sin Restricciones Convexa:
garant√≠a de extremos globales.

o Optimizaci√≥n No Convexa: Primer orden: GD, SGD,
ADAM,

o Optimizaci√≥n No Convexa: Segundo orden: Newton

o Optimizaci√≥n No Convexa: Cero orden: Bayesiana, Powel,

Sim Optimistic Optimization

[o)]]

BIBLIOGRAF√çA
Cybenko, G (1989) Approximation by Superpositions of a Sigmoidal Function, 
https://link.springer.com/article/10.1007/BF02551274
Hornik, Kurk (1990) Approximation capabilities of multilayer feedforward networks,
https://www.sciencedirect.com/science/article/abs/pii/089360809190009T?via%3Dihub
Rumelhart D., Hinton G. & Williams R., Learning representations by back-propagating 
errors. Nature 323, 533-536 (1986), https://doi.org/10.1038/323533a0
Rodrigo Ramele (2024) Reglamento y Apuntes de Sistemas de Inteligencia Artificial, 
Cap√≠tulo 7.

[Descripci√≥n de la imagen: bucareia ojek, i / ojek, i / ojec / ojec / ojec / ojec]

BIAS EN 
PERCEPTR√ìN 
MULTICAPA

[Descripci√≥n de la imagen: una imagen colorida de un cerebro con las palabras ben perpio mutia]

EXTRA: ¬øC√ìMO INCLUYO EL BIAS?
Recordemos que el bias (o umbral) nos permite flexibilizar la forma de la salida 
de la neurona, porque permite desplazamiento de la funci√≥n (ver clase 8)

[Descripci√≥n de la imagen: exo inoco els | Transcripci√≥n de la imagen: EXTRA: ¬øC√ìMO INCLUYO EL BIAS?

Recordemos que el bias (0 umbral) nos permite flexibilizar la forma de la salida

de la neurona, porque permite desplazamiento de la funci√≥n (ver clase 8)

0.7 ¬ªx ‚Äî Republican
¬ªx Democrat
0.6
x
v
E¬£ x ¬ª
n_2 05h
D
√ö
N *
o
¬£ 04
o
=
x
0.3 *
x
* XX
0.2 [ i 1 . L i 1 i
0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8

Normalized Age

Normalized Income

0.7F

o
o
T

a
u

0.4F

0.3F

¬ªx ‚Äî Republican
¬ªx Democrat

0.4 0.5 0.6 0.7 0.8 0.9
Normalized Age]]

Recordemos que el bias (o umbral) nos permite flexibilizar la forma de la salida 
de la neurona, porque permite desplazamiento de la funci√≥n (ver clase 8)
WolframAlpha Link
WolframAlpha Link
EXTRA: ¬øC√ìMO INCLUYO EL BIAS?

[Descripci√≥n de la imagen: exo inclyo els]

EXTRA: ¬øC√ìMO INCLUYO EL BIAS?
Podemos incluir un x0 que permita 
ajustar un peso w0. Este peso ser√° 
equivalente al bias pero puede 
incorporarse en los c√°lculos de manera 
matricial.

[Descripci√≥n de la imagen: exo inclivo els | Transcripci√≥n de la imagen: EXTRA: ¬øC√ìMO INCLUYO EL BIAS?

1
l
l
l
l

Podemos incluir un x, que permita 6 0.445 0.669 10
ajustar un peso w,. Este peso ser√° | 10 l0.349 0.692 10
equivalente al bias pero puede ¬° ** ea ea 10
incorporarse en los c√°lculos de manera | 12 IZZ√ç 3:32 √çZ
matricial. I Io.23 0.529 1.0

I 10 I0.392 0.696 1.0

" | 1.0 |0.355 0.641 1.0

0(x) = 2 X.W + W p o lo.ass 0.66 10
i=1 L L 0 l 1.0 [0.289 0.51 1.0

11(0) | 0.513 0.255 -1.0

I 1.0 |0.755 0.522 -1.0

I 1() IO.626 0.24 -1.0

| E 0.703 0.342 -1.0

| 1.0 I0.863 0.536 -1.0

| 1.0 |0.6 0.225 -1.0

p 9 10.664 0.303 -1.0

1.0 | 0.802 0.565 -1.0

I 1.0 |0.592 0.213 -1.0

I 1.0 0.531 0.223 -1.0]]

EXTRA: ¬øC√ìMO INCLUYO EL BIAS?

[Descripci√≥n de la imagen: un diagrama de un √°rbol con algunos puntos]

1
1
1
EXTRA: ¬øC√ìMO INCLUYO EL BIAS?
Podemos incluir, capa a capa, un valor 
constante para todos los datos de 
entrada, de manera tal que podamos 
ajustar w0 (bias) como si fuera un peso 
sin√°ptico m√°s de la red neuronal.

[Descripci√≥n de la imagen: exo inoly els??????????????????]

RETROPROPAGACI√ìN: NOTACI√ìN
√çndice
Descripci√≥n
i
√≠ndice de la neurona de la capa de salida (o siguiente)
j
√≠ndice de la neurona de la capa intermedia
k
√≠ndice de la neurona de entrada o de la capa 
anterior
m
√≠ndice de la capa intermedia
p
cantidad datos
ùúá
dato en particular
1
1
1
A partir de 
ahora 
comienza 
desde 0

[Descripci√≥n de la imagen: un diagrama de una red con un nodo y un nodo]

1
1
1
EXTRA: ¬øC√ìMO INCLUYO EL BIAS?
¬øEs estrictamente necesario en 
input o en todas las capas? 
No necesariamente, esto pueden 
probarlo. Recordar que el rol del bias 
permite mayor flexibilidad y m√°s 
par√°metros libres para aprender 
patrones cada vez m√°s complejos.
Quiz√°s es posible alcanzar soluciones 
en determinadas situaciones sin hacer 
uso del mismo. Pueden probar ¬øqu√© 
ocurre si no lo incluyo? ¬øsi lo incluyo 
solo en la capa de entrada? ¬øsi lo 
incluyo en todas las capas?

[Descripci√≥n de la imagen: exo inicias??????????????????????]

