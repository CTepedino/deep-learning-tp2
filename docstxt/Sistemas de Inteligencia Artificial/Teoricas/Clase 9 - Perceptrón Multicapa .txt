Primer Cuatrimestre 2025
Sistemas de 
Inteligencia Artificial
PerceptrÃ³n 
Multicapa
Rodrigo Ramele
Eugenia PiÃ±eiro
Alan Pierri
Santiago Reyes
Marina Fuster
Luciano Bianchi
Marco Scilipoti
Paula Oseroff
JoaquÃ­n Girod

[DescripciÃ³n de la imagen: una imagen en blanco y negro de un patrÃ³n colorido, abstracto, fraly, fra - como]

RESUMEN DE LA CLASE ANTERIOR
â—
Â¿QuiÃ©nes son McCulloch y Pitts? Â¿CuÃ¡l fue su aporte?
â—
Â¿QuÃ© tipo de problemas podemos resolver con el perceptrÃ³n 
simple escalÃ³n?
â—
Â¿Con quÃ© mecanismo encuentro los pesos sinÃ¡pticos y el bias?
â—
Â¿QuÃ© tipo de problemas puedo resolver al cambiar la funciÃ³n de 
activaciÃ³n? Por ejemplo: por una lineal o no lineal de la familia 
de sigmoideas.

[DescripciÃ³n de la imagen: resr de la astero ques de la astero ques de la astero]

LIMITACIONES DEL PERCEPTRÃ“N SIMPLE
1
2
1

[DescripciÃ³n de la imagen: un dibujo en lÃ­nea de forma rectangular]

BUSCANDO ALTERNATIVASâ€¦

[DescripciÃ³n de la imagen: un diagrama de una bola y una bola con una lÃ­nea de simetrÃ­a | TranscripciÃ³n de la imagen: BUSCANDO ALTERNATIVAS... I !

â€” 1
Ãjâ€” 9(X) _ 1+exp_28'r
b

Im = (0, 1)]]

BUSCANDO ALTERNATIVASâ€¦
1000
-1000
-2000
1000
-1
1

[DescripciÃ³n de la imagen: un diagrama de un autobÃºs con una luz roja | TranscripciÃ³n de la imagen: BUSCANDO ALTERNATIVAS...

1 B=1
1000
xf
-100
b
1
1 2
o(h)=h
1 -1
B=1
y, â€” 1000]]

Â¿CÃ“MO PUEDO COMBINAR LOS PERCEPTRONES?

[DescripciÃ³n de la imagen: un fondo blanco con las palabras 'como como' y 'como']

Â¿QuÃ© clase de problemas 
puedo representar?

[DescripciÃ³n de la imagen: Que que que que que que que que que que que que que que que que que que que que]

TEOREMA DE APROXIMACIÃ“N UNIVERSAL 
1989 - Cybenko, G.
(expansiÃ³n en 1990, Hornik, K.)

[DescripciÃ³n de la imagen: un grÃ¡fico con dos imÃ¡genes de un hombre y una mujer]

TEOREMA DE APROXIMACIÃ“N UNIVERSAL 
1989 - Cybenko, G.
(expansiÃ³n en 1990, Hornik, K.)

[DescripciÃ³n de la imagen: un grÃ¡fico grÃ¡fico con un grÃ¡fico grÃ¡fico y un grÃ¡fico grÃ¡fico]

TEOREMA DE APROXIMACIÃ“N UNIVERSAL 
1989 - Cybenko, G.
(expansiÃ³n en 1991, Hornik, K.)

[DescripciÃ³n de la imagen: un texto que dice,'tgemaxiom universal ' | TranscripciÃ³n de la imagen: TEOREMA DE APROXIMACIÃ“N UNIVERSAL g|
1989 - Cybenko, G.

(expansiÃ³n en 1991, Hornik, K.)

While the approximating properties we have described are quite powerful, we
have focused only on existence. The important questions that remain to be answered
deal with feasibility, namely how many terms in the summation (or equivalently,
how many neural nodes) are required to yield an approximation of Ã¡ given quality?
What properties of the function being approximated play a role in determining the
number of terms? At this point, we can only say that we suspect quite strongly that
the overwhelming majority of approximation problems will require astronomical
numbers of terms. This feeling is based on the curse of dimensionality that plagues
multidimensional approximation theory and statistics. Some recent progress con-]]

PERCEPTRÃ“N MULTICAPA

[DescripciÃ³n de la imagen: un diagrama de un Ã¡rbol con algunos puntos | TranscripciÃ³n de la imagen: M = cantidad capas

PERCEPTRÃ“N MULTICAPA]]

Â¿CÃ“MO CALCULAMOS LA SALIDA DE LA RED? FEED-FORWARD PASS

[DescripciÃ³n de la imagen: un diagrama de un Ã¡rbol con los nombres de cada uno de los nombres]

Salida de la neurona:
Salida de la neurona de una capa intermedia:
Salida de la neurona de la primera capa intermedia:
Â¿CÃ“MO CALCULAMOS LA SALIDA DE LA RED? FEED-FORWARD PASS

[DescripciÃ³n de la imagen: una imagen de una pantalla de ordenador con las palabras '','''' y'' | TranscripciÃ³n de la imagen: Â¿CÃ“MO CALCULAMOS LA SALIDA DE LA RED? FEED-FORWARD PASS

Salida de la neurona:

= T V . W)
Salida de la neurona de una capa intermedia:

mâ€”1 m
= M =1

Salida de la neurona de la primera capa intermedia:

] 1
= 0(X x .w.)
k=1 ,]]

Â¿CÃ“MO CALCULAMOS LA SALIDA DE LA RED? FEED-FORWARD PASS

[DescripciÃ³n de la imagen: un diagrama de un Ã¡rbol con algunos puntos]

Â¿CÃ“MO VA 
CAMBIANDO EL 
ALGORITMO?

[DescripciÃ³n de la imagen: una pantalla blanca con las palabras 'como' y 'como' | TranscripciÃ³n de la imagen: Initialize multi layer perceptron architecture Â¿CÃ“MO VA

Initialize weights w to small random values

set learning rate n CAMBIAN DO EL
for a fixed number of epochs: ALGORITMO?

For each training example p in the dataset:
1. Compute activation given by feed forward pass:
_ M-1 M
O; = G(Z'K]Vk 'WÂ¡k)'
where j is the index of output neuron,
M is the index of output layer,
k is the index of neuron from previous layer.

sum is over the gty. of neurons from the previous layer.

2. Update the weights and bias:

ece

3. Calculate perceptron error:
erFrOL = EE X) , X)

convergence = True if error < e else False

if convergence: break

End]]

AHORAâ€¦ Â¿CÃ“MO LO ENTRENAMOS? ğŸ‘€

[DescripciÃ³n de la imagen: un diagrama de un Ã¡rbol con un nÃºmero de puntos | TranscripciÃ³n de la imagen: AHORA... Â¿CÃ“MO LO ENTRENAMOS? * *]]

AHORAâ€¦ Â¿CÃ“MO LO ENTRENAMOS? ğŸ‘€
Recordemosâ€¦

[DescripciÃ³n de la imagen: un diagrama de un Ã¡rbol con un nÃºmero de nodos | TranscripciÃ³n de la imagen: AHORA.... Â¿CÃ“MO LO ENTRENAMOS? â‚¬ %]]

AHORAâ€¦ Â¿CÃ“MO LO ENTRENAMOS? ğŸ‘€
Recordemosâ€¦

[DescripciÃ³n de la imagen: un diagrama de un Ã¡rbol con un cÃ­rculo verde | TranscripciÃ³n de la imagen: AHORA.... Â¿CÃ“MO LO ENTRENAMOS? â‚¬ %]]

0.1
-3.4
2
0.6
0.34
-1.2
-0.01
0.86
-1.9
-2.3
0.7
0.02
â€¦
ENTRENAMIENTO: EXPLICACIÃ“N CONCEPTUAL

[DescripciÃ³n de la imagen: un diagrama de un plano con un plano en el medio y un plano en el medio | TranscripciÃ³n de la imagen: ENTRENAMIENTO: EXPLICACIÃ“N CONCEPTUAL]]

ENTRENAMIENTO: EXPLICACIÃ“N CONCEPTUAL
Mecanismo de optimizaciÃ³n: 
por ahora, gradiente 
descendente.
Regla de la cadena de la 
derivada para capas ocultas

[DescripciÃ³n de la imagen: una imagen de un circuito con las palabras en espaÃ±ol]

Ãndice
DescripciÃ³n
i
Ã­ndice de la neurona de la capa de salida (o siguiente)
j
Ã­ndice de la neurona de la capa intermedia
k
Ã­ndice de la neurona de entrada o de la capa anterior
m
Ã­ndice de la capa intermedia
p
cantidad datos
ğœ‡
dato en particular

[DescripciÃ³n de la imagen: un diagrama de un Ã¡rbol con un nÃºmero de nodos]

ENTRENAMIENTO: EXPLICACIÃ“N CONCEPTUAL
â“

[DescripciÃ³n de la imagen: un ejemplo del inter - exor con | TranscripciÃ³n de la imagen: ENTRENAMIENTO: EXPLICACIÃ“N CONCEPTUAL

w wÃ­ Wi
O Ds O s Ã“ME]]

â“
Aplicamos la regla de la cadena:
ENTRENAMIENTO: EXPLICACIÃ“N CONCEPTUAL

[DescripciÃ³n de la imagen: un ejemplo del algoritmo para el algoritmo | TranscripciÃ³n de la imagen: ENTRENAMIENTO: EXPLICACIÃ“N CONCEPTUAL

)) â€” )â€” C) =1

Aplicamos la regla de la cadena:

dE aE 90, AN

6W11 601 6h1 (3W11]]

â“
ENTRENAMIENTO: EXPLICACIÃ“N CONCEPTUAL

[DescripciÃ³n de la imagen: un circuito con un circuito y un circuito con un circuito | TranscripciÃ³n de la imagen: ENTRENAMIENTO: EXPLICACIÃ“N CONCEPTUAL

w wÃ­ Wi
O O u O u Ã“ME]]

â“
Aplicamos la regla de la cadena:
ENTRENAMIENTO: EXPLICACIÃ“N CONCEPTUAL

[DescripciÃ³n de la imagen: un ejemplo del algoritmo para el algoritmo]

â“
ENTRENAMIENTO: EXPLICACIÃ“N CONCEPTUAL

[DescripciÃ³n de la imagen: un circuito con un circuito y un circuito con un circuito | TranscripciÃ³n de la imagen: ENTRENAMIENTO: EXPLICACIÃ“N CONCEPTUAL

w wÃ­ Wi
O O O Ã“ME]]

â“
Aplicamos la regla de la cadena:
ENTRENAMIENTO: EXPLICACIÃ“N CONCEPTUAL

[DescripciÃ³n de la imagen: un ejemplo del algoritmo para el algoritmo | TranscripciÃ³n de la imagen: ENTRENAMIENTO: EXPLICACIÃ“N CONCEPTUAL

w wÃ­ *
O O O Ã“ME

Aplicamos la regla de la cadena:

aE â€” 0E 0, Ã“h, 3V, h

w 90, Ã³h avÃ Ã³h

11]]

RUMELHART, HINTON, WILLIAMS (1986)
â—
Trabajan en un nuevo 
algoritmo para actualizar los 
pesos de una red neuronal 
usando retropropagaciÃ³n 
(backpropagation)
â—
Para calcular la 
actualizaciÃ³n de los pesos 
utilizaremos el algoritmo del 
gradiente descendente y la 
regla de la cadena para la 
diferenciaciÃ³n.
0.1
-3.4
2
0.6
0.34
-1.2
-0.01
0.86
-1.9
-2.3
0.7
0.02
â€¦

[DescripciÃ³n de la imagen: rehart, william william, william, y william]

DELTA: EXPLICACIÃ“N CONCEPTUAL
â“
Aplicamos la regla de la cadena:

[DescripciÃ³n de la imagen: un diagrama del circuito bidimensional | TranscripciÃ³n de la imagen: DELTA: EXPLICACIÃ“N CONCEPTUAL]]

DELTA: EXPLICACIÃ“N CONCEPTUAL
â“
Aplicamos la regla de la cadena:

[DescripciÃ³n de la imagen: del exicio capital | TranscripciÃ³n de la imagen: DELTA: EXPLICACIÃ“N CONCEPTUAL]]

DELTA: EXPLICACIÃ“N CONCEPTUAL
â“
Aplicamos la regla de la cadena:

[DescripciÃ³n de la imagen: del exicio capital | TranscripciÃ³n de la imagen: DELTA: EXPLICACIÃ“N CONCEPTUAL

1 2 W
Wa WÃ­y 11
E) () â€”(7)â€”9) 1=10

Aplicamos la regla de la cadena:]]

Â¿CÃ“MO VA 
CAMBIANDO EL 
ALGORITMO?

[DescripciÃ³n de la imagen: una pantalla blanca con un texto rojo que lee,'comoo alorto???? | TranscripciÃ³n de la imagen: Initialize multi layer perceptron architecture Â¿CÃ“MO VA

Initialize weights w to small random values

set learning rate n CAMBIAN DO EL
for a fixed number of epochs: ALGORITMO?

For each training example p in the dataset:

1. Compute activation given by feed forward pass:
M-1 M
0, = e<%vk 'ij)'

where j is the index of output neuroan,
M is the index of output layer,
k is the index of neuron from previous layer.

sum is over the gty. of neurons from the previous layer.

2. Update the weights and bias:
optimizer (GD) with chain rule
for inner layers (calculated using back-propagation)

3. Calculate perceptron error:
error. = C E <e7 X)
convergence = True if error < e else False

if convergence: break

End]]

Â¿POR QUÃ‰ FUE TAN IMPORTANTE?
â—
Permite resolver el problema de determinar cuÃ¡nto 
contribuye cada neurona al error del perceptrÃ³n 
multicapa de manera eficiente.
â—
Herramienta prÃ¡ctica para aportar evidencia empÃ­rica al 
Teorema de AproximaciÃ³n Universal
â—
Renueva el interÃ©s en el Ã¡rea de inteligencia artificial
â—
El concepto de entrenar redes â€œdeepâ€ se hace posible 
con back propagation

[DescripciÃ³n de la imagen: una imagen de una persona con una cara y un tÃ­tulo]

[DescripciÃ³n de la imagen: una taza de cafÃ© y dos galletas en una tabla de madera]

PERCEPTRÃ“N SIMPLE
PERCEPTRÃ“N MULTICAPA
Proceso para 
obtener la salida 
de la neurona 
(â€œpredecirâ€)
Proceso de 
â€œaprendizajeâ€ 
para ajustar los 
pesos
?
?
?
FunciÃ³n de costo 
(medir error con 
respecto a la 
salida esperada)

[DescripciÃ³n de la imagen: perspilel perspilel perspilel]

PERCEPTRÃ“N SIMPLE
PERCEPTRÃ“N MULTICAPA
Proceso para 
obtener la salida 
de la neurona 
(â€œpredecirâ€)
Proceso de 
â€œaprendizajeâ€ 
para ajustar los 
pesos
FunciÃ³n de costo 
(medir error con 
respecto a la 
salida esperada)
?
?

[DescripciÃ³n de la imagen: perspilel perspilel perspilel perspilel perspilel perspilel perspilel perspilel perspilel perspilel perspilel perspilel perspilel perspilel perspilel perspilel perspilel perspilel perspilel perspilel perspilel perspilel perspilel perspilel pers | TranscripciÃ³n de la imagen: PERCEPTRÃ“N SIMPLE PERCEPTRÃ“N MULTICAPA

Proceso para E â€” mâ€”1 de
obtener la salida Vj 9( ? Vk - ij)
de la neurona k=1

(â€œpredecirâ€) m = 1..M (0.= VÃ­", 5= V?)

FunciÃ³n de costo
(medir error con
respecto a la
salida esperada)

?

A2
E(0) =7ZO(C â€”0)
|_1=

nuevo anterior

Proceso de = w + Aw
â€œaprendizajeâ€ t?
para ajustar los w = - 0E L

pesos T ow]]

PERCEPTRÃ“N SIMPLE
PERCEPTRÃ“N MULTICAPA
Proceso para 
obtener la salida 
de la neurona 
(â€œpredecirâ€)
Proceso de 
â€œaprendizajeâ€ 
para ajustar los 
pesos
?
FunciÃ³n de costo 
(medir error con 
respecto a la 
salida esperada)

[DescripciÃ³n de la imagen: perspilel perspilel perspilel perspilel perspilel perspilel perspilel perspilel perspilel perspilel perspilel perspilel perspilel perspilel perspilel perspilel perspilel perspilel perspilel perspilel perspilel perspilel perspilel perspilel pers | TranscripciÃ³n de la imagen: PERCEPTRÃ“N SIMPLE PERCEPTRÃ“N MULTICAPA

Proceso para
obtener la salida
de la neurona
(â€œpredecirâ€)

mâ€”1 m

m
= e(k;1 ; .)

m=1..M (0,=V",x =V1)

FunciÃ³n de costo
(medir error con
respecto a la
salida esperada)

2

p-1
E(0) =+ 0 -05 E(0) =I -01)
h=0 hi

nuevo anterior
Proceso de 177 = W + Aw
â€œaprendizajeâ€ ?
para ajustar los Ae â€” 0E L
pesos _ u w]]

RETROPROPAGACIÃ“N: NOTACIÃ“N
Ãndice
DescripciÃ³n
i
Ã­ndice de la neurona de la capa de salida (o siguiente)
j
Ã­ndice de la neurona de la capa intermedia
k
Ã­ndice de la neurona de entrada o de la capa anterior
m
Ã­ndice de la capa intermedia
p
cantidad datos
ğœ‡
dato en particular

[DescripciÃ³n de la imagen: propo de propo propo propo propo propo propo propo propo propo propo propo propo propo propo propo propo propo propo propo propo propo propo propo propo propo propo]

RETROPROPAGACIÃ“N: CAPA DE SALIDA (j = M)
Notar que el ejemplo estÃ¡ hecho para un dato de entrada. Se deberÃ¡ extender al conjunto.

[DescripciÃ³n de la imagen: un diagrama del modelo topolÃ³gico para el modelo topolÃ³gico | TranscripciÃ³n de la imagen: E(0) = -E C- 0?>2
RETROPROPAGACIÃ“N: CAPA DE SALIDA ( = M) 0= e(hi)

h =X VÃ­_"'1 .W

j=1 7

w= - dE â€” dE %
W = Maw | â€” _â€”â€Â» aw â€” 00, 0h AW.

Notar que el ejemplo estÃ¡ hecho para un dato de entrada. Se deberÃ¡ extender al conjunto.]]

RETROPROPAGACIÃ“N: CAPA DE SALIDA (j = M)
Notar que el ejemplo estÃ¡ hecho para un dato de entrada. Se deberÃ¡ extender al conjunto.

[DescripciÃ³n de la imagen: un diagrama del algoritmo para el algoritmo | TranscripciÃ³n de la imagen: E(0) = -E C- 0?>2
RETROPROPAGACIÃ“N: CAPA DE SALIDA ( = M) 0= e(hi)

h=y "".w

E E ECAO
W = MNy | â€” â€” oW, â€” 90| an

1

ij

= 6- 0)- 1e017

y

Notar que el ejemplo estÃ¡ hecho para un dato de entrada. Se deberÃ¡ extender al conjunto.]]

RETROPROPAGACIÃ“N: CAPA DE SALIDA (j = M)
Notar que el ejemplo estÃ¡ hecho para un dato de entrada. Se deberÃ¡ extender al conjunto.

[DescripciÃ³n de la imagen: un diagrama del algoritmo para el algoritmo | TranscripciÃ³n de la imagen: E(0) = -E C- 0?>2
RETROPROPAGACIÃ“N: CAPA DE SALIDA ( = M) 0= e(hi)

h=y "".w

E E ECAO
W = MNy | â€” â€” oW, â€” 90| an

ij

0E â€” = ' Mâ€”-1
= 6- 99 DEGY,

0E M-1 ,
w = â€” 6Â¡VÂ¡ 6Â¡ = (ZÂ¡ â€” OÂ¡)9 (hÂ¡)

Notar que el ejemplo estÃ¡ hecho para un dato de entrada. Se deberÃ¡ extender al conjunto.]]

RETROPROPAGACIÃ“N: CAPA DE SALIDA (j = M)
Notar que el ejemplo estÃ¡ hecho para un dato de entrada. Se deberÃ¡ extender al conjunto.

[DescripciÃ³n de la imagen: un diagrama del modelo topolÃ³gico para el modelo topolÃ³gico | TranscripciÃ³n de la imagen: E(0) = -E C- 0?>2
RETROPROPAGACIÃ“N: CAPA DE SALIDA ( = M) 0= e(hi)

h=y "".w

E E ECAO
W = MNy | â€” â€” oW, â€” 90| an

ij

dE _ _ ' M-1
a= 6- 976 96)OY)
0E M-1 ,
6WÂ¡Â¡ â€” 6iVj 6Â¡ â€” (Â¿Â¡ _ 0Â¡)9 (hÂ¡)
â€”1
AWÂ¡Â¡ = T]5Â¡V

Notar que el ejemplo estÃ¡ hecho para un dato de entrada. Se deberÃ¡ extender al conjunto.]]

RETROPROPAGACIÃ“N: CAPA DE SALIDA (j = M)
Notar que el ejemplo estÃ¡ hecho para un dato de entrada. Se deberÃ¡ extender al conjunto.

[DescripciÃ³n de la imagen: un diagrama del modelo topolÃ³gico para el modelo topolÃ³gico | TranscripciÃ³n de la imagen: 2
E(0) =>IE C â€” 05)
hi

RETROPROPAGACIÃ“N: CAPA DE SALIDA ( = M) 0,= O(h)
h 'El VÃ­_"'1 W

E E ECAO
W = MNy | â€” â€” oW, â€” 90| an

ij

dE _ _ ; M-1
a= 6- 976 96)OY)
0E M-1 ,
6WÂ¡Â¡ â€” 6iVj 6Â¡ â€” (Â¿Â¡ _ 0Â¡)9 (hÂ¡)
â€”1
AWÂ¡Â¡ = T]5Â¡V

Notar que el ejemplo estÃ¡ hecho para un dato de entrada. Se deberÃ¡ extender al conjunto.]]

RETROPROPAGACIÃ“N: CAPA OCULTA (j = M-1 , j in [M-1, â€¦, 1])
Notar que el ejemplo estÃ¡ hecho para un dato de entrada. Se deberÃ¡ extender al conjunto.

[DescripciÃ³n de la imagen: un diagrama de un modelo topolÃ³gico]

Notar que el ejemplo estÃ¡ hecho para un dato de entrada. Se deberÃ¡ extender al conjunto.
RETROPROPAGACIÃ“N: CAPA OCULTA (j = M-1 , j in [M-1, â€¦, 1])

[DescripciÃ³n de la imagen: un diagrama del modelo topolÃ³gico para el cuatroier | TranscripciÃ³n de la imagen: 2
E(0) =>IE C â€” 05)
hi

RETROPROPAGACIÃ“N: CAPA OCULTA ( = M-1 , jin [M-1; ..., 1)) 0,= e(h)
h 'El VÃ­_"'1 .W,

JE aE aE 90 Ã“h | av aR

= - Maw| â€” q - [a0 an 9 r

jk j jk
Ã³E ; m m
E =- )X C- 9)0em630W, M "
Ã“W_ Ã³ l 1 1 y a, M m
jk l Ã³hÂ¡' Ã“ij

Notar que el ejemplo estÃ¡ hecho para un dato de entrada. Se deberÃ¡ extender al conjunto.]]

Notar que el ejemplo estÃ¡ hecho para un dato de entrada. Se deberÃ¡ extender al conjunto.
RETROPROPAGACIÃ“N: CAPA OCULTA (j = M-1 , j in [M-1, â€¦, 1])

[DescripciÃ³n de la imagen: un diagrama de la propagaciÃ³n de la propagaciÃ³n de la propagaciÃ³n de la propagaciÃ³n de la propagaciÃ³n de la propagaciÃ³n de | TranscripciÃ³n de la imagen: RETROPROPAGACIÃ“N: CAPA OCULTA (j = M-1 , jin [M-1) ..., 1)

m m
w â€” TE
w | â€” awr - 90 (ah (ay an a

E =- )X â‚¬ - 9)em30)W, 7 *

m m

â€œ
j l â€”â€”â€”â€”.yâ€”â€” 6hÂ¡. Ã³wÂ¡k
Ã“.
i
m m
=. E â€”
a m l l] a 08 , m
Wi, ; Ã“h. Ã³w,
J j jk

Notar que el ejemplo estÃ¡ hecho para un dato de entrada. Se deberÃ¡ extender al conjunto.]]

Notar que el ejemplo estÃ¡ hecho para un dato de entrada. Se deberÃ¡ extender al conjunto.
RETROPROPAGACIÃ“N: CAPA OCULTA (j = M-1 , j in [M-1, â€¦, 1])

[DescripciÃ³n de la imagen: un diagrama de la propagaciÃ³n de la propagaciÃ³n de la propagaciÃ³n de la propagaciÃ³n de la propagaciÃ³n de la propagaciÃ³n de | TranscripciÃ³n de la imagen: m m
= e(1")

m
â€” oe 0 Ã“N V AN
90 Ã“h ay a aw
j jk
0E
m â€”
Ã³wjk
dE m mâ€”1
= - 29W, 0( )01) V
WÂ¡'k a J k

Notar que el ejemplo estÃ¡ hecho para un dato de entrada. Se deberÃ¡ extender al conjunto.]]

RETROPROPAGACIÃ“N: CAPA OCULTA (j = M-1 , j in [M-1, â€¦, 1])

[DescripciÃ³n de la imagen: el diagrama muestra las tres fases del modelo propuesto | TranscripciÃ³n de la imagen: RETROPROPAGACIÃ“N: CAPA OCULTA (j = M-1 , jin [M-1) ..., 1) =y

0E m mâ€”i
E - -â€”y8W Â£
u le ray 0 I 7
87'Il
j
m,,mnâ€”1
Aw = 16.V

j k]]

RETROPROPAGACIÃ“N: CAPA OCULTA (j = M-1 , j in [M-1, â€¦, 1])

[DescripciÃ³n de la imagen: el diagrama muestra las tres fases del modelo propuesto | TranscripciÃ³n de la imagen: RETROPROPAGACIÃ“N: CAPA OCULTA (j = M-1 , jin [M-1) ..., 1) EA]]

Notar que el ejemplo estÃ¡ hecho para un dato de entrada. Se deberÃ¡ extender al conjunto.
RETROPROPAGACIÃ“N: CAPA OCULTA (j in [M-1, â€¦, 1])

[DescripciÃ³n de la imagen: un diagrama de la propagaciÃ³n de la propagaciÃ³n de la propagaciÃ³n de la propagaciÃ³n de la propagaciÃ³n de la propagaciÃ³n de]

PERCEPTRÃ“N SIMPLE
PERCEPTRÃ“N MULTICAPA
Proceso para 
obtener la salida 
de la neurona 
(â€œpredecirâ€)
Proceso de 
â€œaprendizajeâ€ 
para ajustar los 
pesos
FunciÃ³n de costo 
(medir error con 
respecto a la 
salida esperada)

[DescripciÃ³n de la imagen: perspile perspile multila | TranscripciÃ³n de la imagen: PERCEPTRÃ“N SIMPLE PERCEPTRÃ“N MULTICAPA

mâ€”1

= (E V w

j

Proceso para
obtener la salida
de la neurona

(*predecirâ€) m=1..M (0=V, x =V)

FunciÃ³n de costo i pâ€”-1 2 1 " T

(medi â€” H h â€” ! â€”

de E(0) =+ 3 ( -0"  E(0) =0 -0)
h=0 hi

salida esperada)

Proceso de Wnuevo â€” Wanterzor + Aw AWÂ¡Â¡ â€” n6Â¡V]. 6Â¡ "- (Â¿Â¡ _ Âº,-)Âº'(h,)
â€œaprendizajeâ€

para ajustar los â€” dE _

pesos AwW = - , AW;,,;( = n8;,nV;(n - = -C 877 w e'(h")]]

Â¿CÃ“MO VA 
CAMBIANDO EL 
ALGORITMO?
TIP: expresar todo de 
manera matricial 
utilizando alguna 
librerÃ­a como numpy.

[DescripciÃ³n de la imagen: comoo algro | TranscripciÃ³n de la imagen: Initialize multi layer perceptron architecture . CÃ“MO VA
Initialize weights w to small random values Â¿Â¡

CAMBIANDO EL
for a fixed number of epochs: ALGORITMO?

For each training example p in the dataset:

4

Compute activation given by feed forward pass:
M1 â€” M
0; = 9(%EQ .uvâ€œ,

where j is the index of output neuroan,
M is the index of output layer,

TIP: expresar todo de

k is the index of neuron from previous layer. l
sum is over the gty. of neurons from the previous layer. manera matrlC|a

utilizando alguna
Update the weights and bias: librerÃ­a como numpy.

For each weight w.,:

1e

(gradient descendent)

, dE
W: = W: + AWw,, where Aw;: = â€”nÃ³Ã­

0E a o ] 'alacta 1n
and e 15 computed using backpropagation

3. Calculate perceptron error:
error â€” Â£ X) ..7 X)

convergence = True if error < e else False

if convergence: break]]

[DescripciÃ³n de la imagen: una taza de cafÃ© y dos galletas en una tabla de madera]

INCREMENTAL/ONLINE
(Gradiente Descendente 
EstocÃ¡stico)
MINI LOTE/MINI BATCH
(Gradiente Descendente 
EstocÃ¡stico)
LOTE/BATCH
(Gradiente Descendente)
La actualizaciÃ³n de los pesos de 
la red se hace luego de calcular el 
Î”w para un elemento del 
conjunto de datos
La actualizaciÃ³n de los pesos de 
la red se hace luego de calcular el 
Î”w para un subconjunto de 
elementos del conjunto de datos
La actualizaciÃ³n de los pesos de 
la red se hace luego de calcular el 
Î”w para todos los elementos 
del conjunto de datos

[DescripciÃ³n de la imagen: una tabla con tres tipos diferentes de la palabra]

Â¿CÃ“MO VA 
CAMBIANDO EL 
ALGORITMO?
VERSIÃ“N BATCH
TIP: expresar todo de 
manera matricial 
utilizando alguna 
librerÃ­a como numpy.

[DescripciÃ³n de la imagen: comoo algritoo varia | TranscripciÃ³n de la imagen: Initialize multi layer perceptron architecture . CÃ“MO VÂº

Initialize weights w to small random values
p CAMBIANDO EL
â€” ALGORITMO?
Aws = 0 "

For each training example h in the dataset: VE RSIÃ“N BATCH

1. Compute activation given by feed forward pass:

H
(1)

for a fixed number 0

N M
o = 9(2Vk 'W]â€”'-)'

where j is the index of output neuron,
M is the index of output layer, TIP: expresar todo de

k is the index of neuron from previous layer. 1A
â€” ' E E manera matricial
sum is over the gty. of neurons from the previous layer.

utilizando alguna
librerÃ­a como numpy.

2. Calculate the weights and bias:
For each weight w.:

E â€œ . ,
Aws = Aws + Aw,, where Aw, = â€”nÂ¿Ã­ (gradient descendent)

dE

= is computed using backpropagation

and

W=W + Aws
Calculate perceptron error:
error = EC X) ..7 X)
convergence = True if error < e else False

if convergence: break

End]]

â—
Â¿CuÃ¡l es el costo de cada Ã©poca? (aprendizaje) 
â—
Â¿CuÃ¡les son los requerimientos de memoria?
â—
Â¿CÃ³mo manejan el â€œruidoâ€? (ejemplo, outliers)
â—
Â¿CuÃ¡nto tarda en converger?
â—
â€¦
ESTRATEGIAS DE ENTRENAMIENTO: ONLINE / BATCH

[DescripciÃ³n de la imagen: estica entreo / onde / lote]

EJERCICIO

[DescripciÃ³n de la imagen: una pantalla blanca con un texto negro que lee,'' ' | TranscripciÃ³n de la imagen: Initialize
Initialize

multi layer perceptron architecture
weights w to small random values

set learning rate n

for a fixed number of epochs:

End

For each training example p in the dataset:

Compute activation given by feed forward pass:
M-1 M
0; = 6(%Vk W.)-

where j is the index of output neuroan,
M is the index of output layer,

k is the index of neuron from previous layer.

sum is over the gty. of neurons from the previous layer.

. Update the weights and bias:

For each weight w,:

W: = W: + Aw,, where Aw: = â€”nj%% (gradient descendent)

E â€” : 6
and Â¡Â£T is computed using backpropagation

Calculate perceptron error:

error â€” Â£ X) ..7 X)

convergence = True if error < e else False
if convergence: break

EJERCICIO]]

RESUMEN
â—
El perceptrÃ³n multicapa me permite modelar 
transformaciones complejas. En teorÃ­a, cualquier funciÃ³n 
continua puede modelarse con un perceptrÃ³n multicapa.
â—
La arquitectura del perceptÅ•on multicapa debe realizarse 
manualmente. A priori, no tenemos una receta que nos 
permita definir â€œla mejor arquitecturaâ€.
â—
RetropropagaciÃ³n provee un mecanismo con ciertas 
optimizaciones para definir el â€œerrorâ€ en las capas ocultas 
y hallar las actualizaciones de los pesos que nos permiten 
minimizar la funciÃ³n de costo.

[DescripciÃ³n de la imagen: remen e perriza e perriza e perriza e perriza e perriza e perriza e perriza e perriza e perriza e perriza e perriza e perriza e perriza e perriza]

Â¿QuÃ© estoy 
optimizando 
cuando quiero 
usar una red 
neuronal?

[DescripciÃ³n de la imagen: una captura de pantalla de un ordenador con el texto, est est est est est est est est est est | TranscripciÃ³n de la imagen: Â¿QuÃ© estoy
optimizando
cuando quiero
usar una red
neuronal?

FunciÃ³n objetivo

)52Â£1n FO F R = 10 .. (3)
gi(X) <=0 (4)
h(7) =0 (5)

o OptimizaciÃ³n Discreta: ProgramaciÃ³n entera y
combinatoria

o OptimizaciÃ³n Discreta: EcuaciÃ³n diofÃ¡ntica

o OptimizaciÃ³n Lineal: ProgramaciÃ³n Lineal

o OptimizaciÃ³n No Lineal sin Restricciones Convexa:
garantÃ­a de extremos globales.

o OptimizaciÃ³n No Convexa: Primer orden: GD, SGD,
ADAM,

o OptimizaciÃ³n No Convexa: Segundo orden: Newton

o OptimizaciÃ³n No Convexa: Cero orden: Bayesiana, Powel,

Sim Optimistic Optimization

[o)]]

BIBLIOGRAFÃA
Cybenko, G (1989) Approximation by Superpositions of a Sigmoidal Function, 
https://link.springer.com/article/10.1007/BF02551274
Hornik, Kurk (1990) Approximation capabilities of multilayer feedforward networks,
https://www.sciencedirect.com/science/article/abs/pii/089360809190009T?via%3Dihub
Rumelhart D., Hinton G. & Williams R., Learning representations by back-propagating 
errors. Nature 323, 533-536 (1986), https://doi.org/10.1038/323533a0
Rodrigo Ramele (2024) Reglamento y Apuntes de Sistemas de Inteligencia Artificial, 
CapÃ­tulo 7.

[DescripciÃ³n de la imagen: bucareia ojek, i / ojek, i / ojec / ojec / ojec / ojec]

BIAS EN 
PERCEPTRÃ“N 
MULTICAPA

[DescripciÃ³n de la imagen: una imagen colorida de un cerebro con las palabras ben perpio mutia]

EXTRA: Â¿CÃ“MO INCLUYO EL BIAS?
Recordemos que el bias (o umbral) nos permite flexibilizar la forma de la salida 
de la neurona, porque permite desplazamiento de la funciÃ³n (ver clase 8)

[DescripciÃ³n de la imagen: exo inoco els | TranscripciÃ³n de la imagen: EXTRA: Â¿CÃ“MO INCLUYO EL BIAS?

Recordemos que el bias (0 umbral) nos permite flexibilizar la forma de la salida

de la neurona, porque permite desplazamiento de la funciÃ³n (ver clase 8)

0.7 Â»x â€” Republican
Â»x Democrat
0.6
x
v
EÂ£ x Â»
n_2 05h
D
Ãš
N *
o
Â£ 04
o
=
x
0.3 *
x
* XX
0.2 [ i 1 . L i 1 i
0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8

Normalized Age

Normalized Income

0.7F

o
o
T

a
u

0.4F

0.3F

Â»x â€” Republican
Â»x Democrat

0.4 0.5 0.6 0.7 0.8 0.9
Normalized Age]]

Recordemos que el bias (o umbral) nos permite flexibilizar la forma de la salida 
de la neurona, porque permite desplazamiento de la funciÃ³n (ver clase 8)
WolframAlpha Link
WolframAlpha Link
EXTRA: Â¿CÃ“MO INCLUYO EL BIAS?

[DescripciÃ³n de la imagen: exo inclyo els]

EXTRA: Â¿CÃ“MO INCLUYO EL BIAS?
Podemos incluir un x0 que permita 
ajustar un peso w0. Este peso serÃ¡ 
equivalente al bias pero puede 
incorporarse en los cÃ¡lculos de manera 
matricial.

[DescripciÃ³n de la imagen: exo inclivo els | TranscripciÃ³n de la imagen: EXTRA: Â¿CÃ“MO INCLUYO EL BIAS?

1
l
l
l
l

Podemos incluir un x, que permita 6 0.445 0.669 10
ajustar un peso w,. Este peso serÃ¡ | 10 l0.349 0.692 10
equivalente al bias pero puede Â¡ ** ea ea 10
incorporarse en los cÃ¡lculos de manera | 12 IZZÃ 3:32 ÃZ
matricial. I Io.23 0.529 1.0

I 10 I0.392 0.696 1.0

" | 1.0 |0.355 0.641 1.0

0(x) = 2 X.W + W p o lo.ass 0.66 10
i=1 L L 0 l 1.0 [0.289 0.51 1.0

11(0) | 0.513 0.255 -1.0

I 1.0 |0.755 0.522 -1.0

I 1() IO.626 0.24 -1.0

| E 0.703 0.342 -1.0

| 1.0 I0.863 0.536 -1.0

| 1.0 |0.6 0.225 -1.0

p 9 10.664 0.303 -1.0

1.0 | 0.802 0.565 -1.0

I 1.0 |0.592 0.213 -1.0

I 1.0 0.531 0.223 -1.0]]

EXTRA: Â¿CÃ“MO INCLUYO EL BIAS?

[DescripciÃ³n de la imagen: un diagrama de un Ã¡rbol con algunos puntos]

1
1
1
EXTRA: Â¿CÃ“MO INCLUYO EL BIAS?
Podemos incluir, capa a capa, un valor 
constante para todos los datos de 
entrada, de manera tal que podamos 
ajustar w0 (bias) como si fuera un peso 
sinÃ¡ptico mÃ¡s de la red neuronal.

[DescripciÃ³n de la imagen: exo inoly els??????????????????]

RETROPROPAGACIÃ“N: NOTACIÃ“N
Ãndice
DescripciÃ³n
i
Ã­ndice de la neurona de la capa de salida (o siguiente)
j
Ã­ndice de la neurona de la capa intermedia
k
Ã­ndice de la neurona de entrada o de la capa 
anterior
m
Ã­ndice de la capa intermedia
p
cantidad datos
ğœ‡
dato en particular
1
1
1
A partir de 
ahora 
comienza 
desde 0

[DescripciÃ³n de la imagen: un diagrama de una red con un nodo y un nodo]

1
1
1
EXTRA: Â¿CÃ“MO INCLUYO EL BIAS?
Â¿Es estrictamente necesario en 
input o en todas las capas? 
No necesariamente, esto pueden 
probarlo. Recordar que el rol del bias 
permite mayor flexibilidad y mÃ¡s 
parÃ¡metros libres para aprender 
patrones cada vez mÃ¡s complejos.
QuizÃ¡s es posible alcanzar soluciones 
en determinadas situaciones sin hacer 
uso del mismo. Pueden probar Â¿quÃ© 
ocurre si no lo incluyo? Â¿si lo incluyo 
solo en la capa de entrada? Â¿si lo 
incluyo en todas las capas?

[DescripciÃ³n de la imagen: exo inicias??????????????????????]

