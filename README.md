# Sistema RAG para GeneraciÃ³n de Ejercicios AcadÃ©micos

Sistema de Retrieval-Augmented Generation (RAG) diseÃ±ado para generar ejercicios acadÃ©micos basados en materiales oficiales de la carrera de IngenierÃ­a InformÃ¡tica del ITBA.

**MVP**: Soporte para **Probabilidad y estadÃ­stica** y **Sistemas de Inteligencia Artificial (SIA)**.

## ğŸ¯ CaracterÃ­sticas

- **Carga flexible de documentos**: Soporte para PDF, TXT y TEX
- **FragmentaciÃ³n inteligente**: Splitting optimizado para documentos acadÃ©micos
- **Embeddings con LangChain**: IntegraciÃ³n completa con ecosistema LangChain
- **Base de datos vectorial**: ChromaDB con persistencia automÃ¡tica
- **BÃºsqueda semÃ¡ntica**: Con filtros por materia, tipo y dificultad
- **GeneraciÃ³n de ejercicios**: 4 tipos diferentes con OpenAI
- **Metadata acadÃ©mica**: DetecciÃ³n automÃ¡tica de materias (Probabilidad y estadÃ­stica, SIA) y tipos de documento
- **Arquitectura estÃ¡ndar**: Usando LangChain para mÃ¡xima flexibilidad

## ğŸ“š Materias Soportadas (MVP)

- **Probabilidad y estadÃ­stica**: Ejercicios matemÃ¡ticos y simbÃ³licos
- **Sistemas de Inteligencia Artificial (SIA)**: Ejercicios teÃ³ricos y conceptuales

## ğŸ“‹ Tipos de Ejercicios Soportados

- **multiple_choice**: Preguntas de opciÃ³n mÃºltiple (A, B, C, D)
- **desarrollo**: Preguntas de desarrollo teÃ³rico
- **practico**: Problemas prÃ¡cticos con cÃ¡lculos
- **teorico**: Preguntas conceptuales teÃ³ricas

## ğŸš€ InstalaciÃ³n

### 1. Clonar el repositorio
```bash
git clone <repository-url>
cd deep-learning-tp2
```

### 2. Instalar dependencias
```bash
pip install -r requirements.txt
```

### 3. Configurar variables de entorno
```bash
# Copiar archivo de ejemplo
cp env.example .env

# Editar .env con tus API keys
nano .env
```

Variables requeridas:
```env
OPENAI_API_KEY=tu_api_key_aqui
```

Variables opcionales:
```env
HF_TOKEN=tu_huggingface_token
EMBEDDING_PROVIDER=huggingface  # o "openai"
LLM_MODEL=gpt-4o-mini
CHUNK_SIZE=1000
CHUNK_OVERLAP=200
```

## ğŸ“– Uso BÃ¡sico

### 1. Inicializar el sistema
```python
from src.rag_pipeline import create_rag_pipeline

# Crear pipeline RAG
rag_pipeline = create_rag_pipeline(
    collection_name="itba_ejercicios",
    embedding_model="all-MiniLM-L6-v2",  # Modelo por defecto
    reset_collection=False
)
```

### 2. Cargar materiales acadÃ©micos
```python
# Cargar desde directorio
result = rag_pipeline.load_materials(
    directory_path="./data/raw",
    use_academic_metadata=True
)

print(f"Documentos cargados: {result['documents_loaded']}")
print(f"Chunks creados: {result['chunks_created']}")
```

### 3. Generar ejercicios
```python
# ParÃ¡metros de la consulta
query_params = {
    "materia": "Probabilidad y estadÃ­stica",
    "unidad": "DistribuciÃ³n normal",
    "cantidad": 3,
    "nivel_dificultad": "intermedio",
    "tipo_ejercicio": "multiple_choice"
}

# Generar ejercicios
result = rag_pipeline.generate_exercises(
    query_params=query_params,
    tipo_ejercicio="multiple_choice",
    k_retrieval=5
)

# Mostrar resultados
for i, exercise in enumerate(result['ejercicios'], 1):
    print(f"Ejercicio {i}: {exercise['pregunta']}")
    print(f"Opciones: {exercise['opciones']}")
    print(f"Respuesta: {exercise['respuesta_correcta']}")
```

## ğŸ“ Estructura del Proyecto

```
deep-learning-tp2/
â”œâ”€â”€ src/                          # CÃ³digo fuente
â”‚   â”œâ”€â”€ data_loading.py          # Carga de documentos
â”‚   â”œâ”€â”€ text_processing.py       # FragmentaciÃ³n de texto
â”‚   â”œâ”€â”€ vector_store.py          # ChromaDB con LangChain
â”‚   â”œâ”€â”€ retriever.py             # Retriever con LangChain
â”‚   â”œâ”€â”€ query_utils.py           # ConstrucciÃ³n de consultas
â”‚   â”œâ”€â”€ generator.py             # GeneraciÃ³n con LLM
â”‚   â””â”€â”€ rag_pipeline.py          # Pipeline principal
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                     # Materiales originales
â”‚   â””â”€â”€ processed/               # ChromaDB persistente
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ rag_demo.ipynb          # Demo completo
â”œâ”€â”€ requirements.txt             # Dependencias con LangChain
â”œâ”€â”€ env.example                  # Template de variables
â””â”€â”€ README.md                    # Este archivo
```

## ğŸ”§ ConfiguraciÃ³n Avanzada

### Cambiar modelo de embeddings
```python
# Usar modelo diferente de sentence-transformers
rag_pipeline = create_rag_pipeline(
    embedding_model="all-mpnet-base-v2"  # Mayor calidad, mÃ¡s lento
)
```

### Modelos disponibles
- `all-MiniLM-L6-v2` (384 dims) - RÃ¡pido y eficiente (por defecto)
- `all-mpnet-base-v2` (768 dims) - Mayor calidad
- `multi-qa-MiniLM-L6-cos-v1` (384 dims) - Optimizado para Q&A

### Configurar generador
```python
# Ajustar creatividad
rag_pipeline.update_generator_settings(
    model_name="gpt-4o",     # Modelo mÃ¡s potente
    temperature=0.8          # MÃ¡s creativo
)
```

## ğŸ“Š Ejemplo de Output

```json
{
  "ejercicios": [
    {
      "pregunta": "Â¿CuÃ¡l es la probabilidad de que una variable aleatoria normal estÃ¡ndar sea menor que 1.96?",
      "opciones": [
        "0.95",
        "0.975", 
        "0.025",
        "0.05"
      ],
      "respuesta_correcta": "B",
      "pista": "Usa la tabla de la distribuciÃ³n normal estÃ¡ndar",
      "solucion": "Para Z ~ N(0,1), P(Z < 1.96) = 0.975 segÃºn la tabla estÃ¡ndar."
    }
  ],
  "metadata": {
    "materia": "Probabilidad y estadÃ­stica",
    "unidad": "DistribuciÃ³n normal",
    "tipo_ejercicio": "multiple_choice",
    "cantidad": 1,
    "nivel_dificultad": "intermedio",
    "chunks_recuperados": 5,
    "fuentes": ["apunte_probabilidad.pdf", "guia_ejercicios.pdf"],
    "modelo_usado": "gpt-4o-mini"
  }
}
```

## ğŸ§ª Demo Interactivo

Ejecuta el notebook de demostraciÃ³n:
```bash
jupyter notebook notebooks/rag_demo.ipynb
```

El demo incluye:
- ConfiguraciÃ³n del sistema
- Carga de materiales de ejemplo
- GeneraciÃ³n de diferentes tipos de ejercicios
- AnÃ¡lisis del sistema
- Ejemplos de uso avanzado

## ğŸ” BÃºsqueda de Materiales

```python
# BÃºsqueda bÃ¡sica
results = rag_pipeline.search_materials(
    query="distribuciÃ³n normal",
    k=5
)

# BÃºsqueda con filtros
results = rag_pipeline.search_materials(
    query="algoritmos",
    k=3,
    filter_dict={"materia": "Sistemas de Inteligencia Artificial"}
)
```

## ğŸ“ˆ MÃ©tricas y AnÃ¡lisis

```python
# Obtener informaciÃ³n del sistema
info = rag_pipeline.get_system_info()
print(f"Documentos en vector store: {info['vector_store']['document_count']}")
print(f"Modelo de embeddings: {info['embeddings']['model_name']}")
print(f"DimensiÃ³n de embeddings: {info['embeddings']['embedding_dimension']}")
```

## ğŸ› ï¸ Desarrollo

### Agregar nuevos tipos de ejercicios
1. Editar `src/generator.py`
2. Agregar template en `_setup_prompts()`
3. Implementar funciÃ³n de validaciÃ³n
4. Actualizar documentaciÃ³n

### Agregar nuevos formatos de documento
1. Editar `src/data_loading.py`
2. Agregar loader en `DocumentLoader.__init__()`
3. Implementar extractor de metadata si es necesario

## ğŸ› SoluciÃ³n de Problemas

### Error: "OPENAI_API_KEY no encontrada"
- Verifica que el archivo `.env` existe y contiene la API key
- AsegÃºrate de cargar las variables con `load_dotenv()`

### Error: "No se encontrÃ³ contexto relevante"
- Verifica que los materiales estÃ¡n cargados en el vector store
- Ajusta los parÃ¡metros de bÃºsqueda (`k_retrieval`)
- Revisa que la consulta sea especÃ­fica

### Error: "ChromaDB no se puede conectar"
- Verifica permisos de escritura en `data/processed/`
- Elimina la colecciÃ³n existente si es necesario (`reset_collection=True`)

## ğŸ“ Notas Importantes

- **Materiales acadÃ©micos**: El sistema estÃ¡ optimizado para documentos del ITBA (Probabilidad y estadÃ­stica, SIA)
- **LangChain Integration**: Usa el ecosistema estÃ¡ndar de LangChain para mÃ¡xima flexibilidad
- **Persistencia**: ChromaDB guarda embeddings en disco para reutilizaciÃ³n
- **Metadata**: El sistema detecta automÃ¡ticamente materias y tipos de documento
- **Arquitectura estÃ¡ndar**: Compatible con el ecosistema completo de LangChain

## ğŸ¤ Contribuciones

1. Fork el proyecto
2. Crea una rama para tu feature (`git checkout -b feature/nueva-funcionalidad`)
3. Commit tus cambios (`git commit -am 'Agregar nueva funcionalidad'`)
4. Push a la rama (`git push origin feature/nueva-funcionalidad`)
5. Abre un Pull Request

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la Licencia MIT. Ver `LICENSE` para mÃ¡s detalles.

## ğŸ“ Soporte

Para preguntas o problemas:
- Abre un issue en GitHub
- Revisa la documentaciÃ³n en `notebooks/rag_demo.ipynb`
- Consulta los logs del sistema para debugging

---

**Desarrollado para el TP2 de Deep Learning - ITBA**
