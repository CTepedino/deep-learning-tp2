#!/usr/bin/env python3
"""
Script simple para probar el sistema RAG y generar ejercicios
"""

import os
import sys
from pathlib import Path
from dotenv import load_dotenv

# Agregar el directorio raÃ­z al path para que funcionen las importaciones
sys.path.insert(0, str(Path(__file__).parent))

from src.rag_pipeline import create_rag_pipeline

def main():
    print("\n" + "=" * 70)
    print("ðŸŽ“ SISTEMA RAG - GENERADOR DE EJERCICIOS ACADÃ‰MICOS")
    print("=" * 70)
    print("Demo interactiva del pipeline completo")
    print("Este script muestra cada paso del proceso RAG:")
    print("  1ï¸âƒ£  ConfiguraciÃ³n y variables de entorno")
    print("  2ï¸âƒ£  InicializaciÃ³n del pipeline")
    print("  3ï¸âƒ£  Estado de la base de datos vectorial")
    print("  4ï¸âƒ£  GeneraciÃ³n de ejercicios con contexto")
    print("=" * 70)
    
    # 1. Cargar variables de entorno
    print("\n" + "=" * 70)
    print("ðŸ“‹ PASO 1: CONFIGURACIÃ“N")
    print("=" * 70)
    print("\nâ³ Cargando variables de entorno desde .env...")
    load_dotenv()
    
    # Verificar archivo .env
    env_file = Path('.env')
    if not env_file.exists():
        print("âš ï¸  Archivo .env no encontrado. Usando env.example")
        load_dotenv('env.example')
    
    if not os.getenv('OPENAI_API_KEY') or os.getenv('OPENAI_API_KEY') == 'your_openai_api_key_here':
        print("âŒ ERROR: Necesitas configurar tu OPENAI_API_KEY en el archivo .env")
        print("   1. Copia env.example a .env: cp env.example .env")
        print("   2. Edita .env y agrega tu API key de OpenAI")
        return
    
    print("âœ… Variables de entorno cargadas:")
    print(f"   - OPENAI_API_KEY: {'*' * 20}{os.getenv('OPENAI_API_KEY')[-4:]}")
    print(f"   - EMBEDDING_MODEL: {os.getenv('EMBEDDING_MODEL', 'all-MiniLM-L6-v2')}")
    print(f"   - LLM_MODEL: {os.getenv('LLM_MODEL', 'gpt-4o-mini')}")
    print(f"   - CHUNK_SIZE: {os.getenv('CHUNK_SIZE', '1000')}")
    
    # 2. Inicializar pipeline
    print("\n" + "=" * 70)
    print("ðŸ“‹ PASO 2: INICIALIZACIÃ“N DEL PIPELINE")
    print("=" * 70)
    print("\nâ³ Creando componentes del sistema RAG...")
    
    # Crear pipeline sin parÃ¡metros para que lea TODO del .env
    rag_pipeline = create_rag_pipeline(
        reset_collection=False  # No reiniciar si ya hay datos
    )
    
    # Mostrar quÃ© configuraciÃ³n se estÃ¡ usando
    system_info = rag_pipeline.get_system_info()
    embedding_model = system_info['vector_store']['embedding_model']
    doc_count = system_info['vector_store']['document_count']
    
    print(f"\nâœ… Pipeline inicializado con Ã©xito")
    print(f"\nðŸ“¦ Componentes creados:")
    print(f"   1. Vector Store:")
    print(f"      - Tipo: {system_info['vector_store']['type']}")
    print(f"      - ColecciÃ³n: {system_info['vector_store']['collection_name']}")
    print(f"      - Embeddings: {embedding_model}")
    print(f"   2. Retriever:")
    print(f"      - k (docs a recuperar): {system_info['retriever']['k']}")
    print(f"      - Score threshold: {system_info['retriever']['score_threshold']}")
    print(f"   3. Generator:")
    print(f"      - Modelo LLM: {system_info['generator']['model']}")
    print(f"   4. Text Processor:")
    print(f"      - Chunk size: {system_info['text_processing']['chunk_size']}")
    print(f"      - Chunk overlap: {system_info['text_processing']['chunk_overlap']}")
    
    # 3. Verificar si hay documentos cargados
    print("\n" + "=" * 70)
    print("ðŸ“‹ PASO 3: ESTADO DE LA BASE DE DATOS")
    print("=" * 70)
    
    print(f"\nðŸ“Š Documentos en el sistema: {doc_count}")
    
    print("\nâ³ Cargando todos los materiales...")
    print("   (Esto puede tomar unos minutos la primera vez)")
    
    # Cargar todos los materiales desde docs
    result = rag_pipeline.load_materials(
        data_directory="./docs",
        skip_on_error=True  # Continuar si hay errores
    )
    
    # Manejar diferentes estados
    status = result.get('status')
    
    if status == 'error' and not result.get('can_continue'):
        print(f"âŒ Error crÃ­tico: {result.get('message')}")
        return
    elif status == 'partial_error':
        print(f"\nâš ï¸  Error parcial al cargar nuevos documentos:")
        print(f"   {result.get('message')}")
        print(f"\nâœ… Continuando con {result.get('existing_documents', 0)} documentos existentes")
    elif status == 'warning':
        print(f"\nâš ï¸  {result.get('message')}")
        print(f"   Usando documentos existentes para generar ejercicios")
    elif status == 'success':
        print(f"\nâœ… Carga completada:")
        print(f"   - Documentos procesados: {result['documents_loaded']}")
        print(f"   - Chunks generados: {result['chunks_created']}")
        print(f"   - IDs asignados: {result['documents_added']}")
    
    # 3.1 Mostrar ejemplos de chunks
    print("\nðŸ“– Mostrando ejemplos de chunks almacenados...")
    sample_results = rag_pipeline.search_materials(
        query="probabilidad variables aleatorias",
        k=3
    )
    
    if sample_results:
        for i, doc in enumerate(sample_results[:2], 1):
            print(f"\nðŸ”¹ Chunk de ejemplo {i}:")
            content_preview = doc['content'][:200] + "..." if len(doc['content']) > 200 else doc['content']
            print(f"   Contenido: {content_preview}")
            print(f"   Metadata:")
            for key, value in doc['metadata'].items():
                if key not in ['page', 'start_index']:  # Omitir metadata menos relevante
                    print(f"      - {key}: {value}")
    
    # 3.2 Analizar metadata
    print("\nðŸ“Š AnÃ¡lisis de metadata...")
    all_docs = rag_pipeline.search_materials(query="", k=100)
    
    if all_docs:
        materias = set()
        tipos_doc = set()
        difficulty_levels = set()
        
        for doc in all_docs:
            metadata = doc['metadata']
            if 'materia' in metadata:
                materias.add(metadata['materia'])
            if 'tipo_documento' in metadata:
                tipos_doc.add(metadata['tipo_documento'])
            if 'difficulty_hint' in metadata:
                difficulty_levels.add(metadata['difficulty_hint'])
        
        print(f"   - Materias detectadas: {', '.join(materias) if materias else 'N/A'}")
        print(f"   - Tipos de documento: {', '.join(tipos_doc) if tipos_doc else 'N/A'}")
        print(f"   - Niveles de dificultad: {', '.join(difficulty_levels) if difficulty_levels else 'N/A'}")
    
    # 4. Generar ejercicio de prueba
    print("\n" + "=" * 70)
    print("ðŸ“‹ PASO 4: GENERACIÃ“N DE EJERCICIOS")
    print("=" * 70)
    
    query_params = {
        "materia": "Probabilidad y estadÃ­stica",
        "unidad": "Variables Aleatorias",
        "cantidad": 1,
        "nivel_dificultad": "intermedio",
        "tipo_ejercicio": "multiple_choice"
    }
    
    print(f"\nðŸ“ ParÃ¡metros de generaciÃ³n:")
    for key, value in query_params.items():
        print(f"   - {key}: {value}")
    
    # 4.1 Primero mostrar quÃ© documentos se recuperarÃ­an
    print("\nðŸ” Recuperando contexto relevante...")
    from src.query_utils import prepare_search_query
    search_query = prepare_search_query(query_params)
    print(f"   Query de bÃºsqueda: '{search_query}'")
    
    context_preview = rag_pipeline.search_materials(
        query=search_query,
        k=5
    )
    
    if context_preview:
        print(f"\nðŸ“š Se recuperaron {len(context_preview)} chunks de contexto:")
        for i, doc in enumerate(context_preview[:3], 1):
            content_snippet = doc['content'][:100].replace('\n', ' ') + "..."
            source = doc['metadata'].get('source', 'desconocido')
            print(f"   {i}. [{source}] {content_snippet}")
    
    # 4.2 Generar ejercicio
    print("\nâ³ Generando ejercicio con LLM...")
    result = rag_pipeline.generate_exercises(
        query_params=query_params,
        k_retrieval=5
    )
    
    # Verificar si hubo error
    if result.get('status') == 'error':
        print(f"âŒ Error: {result.get('message')}")
        return
    
    # 5. Mostrar resultados
    print("\n" + "=" * 70)
    print("âœ¨ EJERCICIO GENERADO")
    print("=" * 70)
    
    if 'ejercicios' not in result or not result['ejercicios']:
        print("âš ï¸ No se generaron ejercicios")
        return
    
    for i, exercise in enumerate(result['ejercicios'], 1):
        print(f"\nâ”Œ{'â”€' * 68}â”")
        print(f"â”‚ ðŸ“ EJERCICIO {i}")
        print(f"â””{'â”€' * 68}â”˜")
        print(f"\n{exercise['pregunta']}")
        print(f"\nOpciones:")
        opciones_letras = ['A', 'B', 'C', 'D']
        for j, opcion in enumerate(exercise['opciones']):
            print(f"  {opciones_letras[j]}) {opcion}")
        
        print(f"\nâœ… Respuesta correcta: {exercise['respuesta_correcta']}")
        
        if 'pista' in exercise and exercise['pista']:
            print(f"\nðŸ’¡ Pista: {exercise['pista']}")
        
        if 'solucion' in exercise and exercise['solucion']:
            print(f"\nðŸ“– SoluciÃ³n: {exercise['solucion']}")
    
    # Metadata del proceso
    print("\n" + "=" * 70)
    print("ðŸ“Š METADATA DEL PROCESO DE GENERACIÃ“N")
    print("=" * 70)
    
    metadata = result.get('metadata', {})
    context_info = result.get('context_info', {})
    
    print(f"\nðŸ“‹ ParÃ¡metros usados:")
    print(f"   - Materia: {metadata.get('materia', 'N/A')}")
    print(f"   - Unidad: {metadata.get('unidad', 'N/A')}")
    print(f"   - Tipo: {metadata.get('tipo_ejercicio', 'N/A')}")
    print(f"   - Dificultad: {metadata.get('nivel_dificultad', 'N/A')}")
    
    print(f"\nðŸ” Proceso de retrieval:")
    print(f"   - Query de bÃºsqueda: '{context_info.get('search_query', 'N/A')}'")
    print(f"   - Chunks recuperados: {metadata.get('chunks_recuperados', 0)}")
    print(f"   - Filtros aplicados: {context_info.get('filters_applied', 'Ninguno')}")
    
    print(f"\nðŸ¤– GeneraciÃ³n:")
    print(f"   - Modelo LLM: {metadata.get('modelo_usado', 'N/A')}")
    
    if 'fuentes' in metadata and metadata['fuentes']:
        print(f"\nðŸ“š Fuentes utilizadas:")
        unique_sources = list(set(metadata['fuentes']))[:5]
        for source in unique_sources:
            source_name = source.split('/')[-1] if '/' in source else source
            print(f"   - {source_name}")
        if len(unique_sources) > 5:
            print(f"   ... y {len(unique_sources) - 5} mÃ¡s")
    
    print("\n" + "=" * 70)
    print("âœ… Â¡DEMO COMPLETADA EXITOSAMENTE!")
    print("=" * 70)
    
    # Opciones adicionales
    print("\nðŸ’¡ Para generar mÃ¡s ejercicios, puedes:")
    print("   - Modificar los query_params en este script")
    print("   - Probar diferentes tipos: 'desarrollo', 'practico', 'teorico'")
    print("   - Cambiar la materia a 'Sistemas de Inteligencia Artificial'")
    print("   - Ajustar la dificultad: 'basico', 'intermedio', 'avanzado'")

if __name__ == "__main__":
    main()

